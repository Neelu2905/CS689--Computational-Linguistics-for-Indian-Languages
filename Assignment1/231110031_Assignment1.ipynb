{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0buztC6Dg3b"
   },
   "source": [
    "**QUESTION 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOVwnL9lZg7u"
   },
   "source": [
    "**FUNCTION TO CORRECT UNICODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Gj3-4MHm-1nx"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the contents of the text file\n",
    "with open('hi_100_up.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Define a regular expression pattern to match English words\n",
    "english_pattern = re.compile(r'[a-zA-Z]+')\n",
    "\n",
    "# Iterate through each line in the corpus\n",
    "clean_corpus = []\n",
    "for line in corpus:\n",
    "    # Tokenize the line and remove English words\n",
    "    tokens = line.split()  # Assuming space-separated tokens\n",
    "    tokens = [token for token in tokens if not re.match(english_pattern, token)]\n",
    "    cleaned_line = ' '.join(tokens)\n",
    "    clean_corpus.append(cleaned_line)\n",
    "\n",
    "# Join the lines back into a single text\n",
    "clean_text = '\\n'.join(clean_corpus)\n",
    "\n",
    "# Optionally, write the clean text back to a file\n",
    "with open('hi_100_up.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7VurV1IzCRSo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Array containing all the consonants in Devanagari script\n",
    "hindi_consonants = [\n",
    "    'क', 'ख', 'ग', 'घ', 'ङ',\n",
    "    'च', 'छ', 'ज', 'झ', 'ञ',\n",
    "    'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
    "    'त', 'थ', 'द', 'ध', 'न',\n",
    "    'प', 'फ', 'ब', 'भ', 'म',\n",
    "    'य', 'र', 'ल', 'व', 'श',\n",
    "    'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'\n",
    "]\n",
    "\n",
    "# Array containing all the vowels in Devanagari script\n",
    "hindi_vowels = ['अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ']\n",
    "\n",
    "# Array containing all the matras in Devanagari script\n",
    "hindi_matras = ['ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'े', 'ै', 'ो', 'ौ', 'ॄ']\n",
    "\n",
    "# Array containing mapping of matras with vowels in Devanagari script\n",
    "hindi_vowel_matras = {\"ा\":\"आ\",\"ि\":\"इ\",\"ी\":\"ई\",\"ु\":\"उ\",\"ू\":\"ऊ\",\"े\":\"ए\",\"ै\":\"ऐ\",\"ो\":\"ओ\",\"ौ\":\"औ\", \"ं\":\"अं\",\"ृ\":\"ऋ\",'ॉ':\"ऑ\", 'ॄ': \"ॠ\" }\n",
    "\n",
    "# Array containing garbage characters\n",
    "garbage = [\"_\", \"०\", \"S\", \"―\", \"=\", \"[\", \"]\", \"......\", \"।\", \";\", \",\",\":\", \"!\", '\"', \"?\", \":-\", \"-\", \"{\", \"(\", \"}\", \")\", \":-\", \".\", \"॥\", '”', \"|\"]\n",
    "\n",
    "with open('hi_100_up.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "    # Remove garbage characters from the content\n",
    "    for char in garbage:\n",
    "        content = content.replace(char, '')\n",
    "    # Split the content into words\n",
    "    words = content.split()\n",
    "\n",
    "# Function to check if a word contains only Hindi characters\n",
    "def is_hindi(word):\n",
    "    hindi_chars = set(\"् अ अ आ अं  ं इ ई उ ऊ ए ऐ ओ औ ऋ क ख ग घ ङ च छ ज झ ञ ट ठ ड ढ ण त थ द ध न प फ ब भ म य र ल व श ष स ह ळ क्ष ज्ञ र्ड र्ढ ॐ । ॥ ा  ि  ी  ु  ू  ृ  ॄ  े  ै  ो  ौ  ॄ \".split())\n",
    "    return all(char in hindi_chars for char in word)\n",
    "\n",
    "# Filter out non-Hindi words\n",
    "hindi_words_unicode = [word for word in words if is_hindi(word)]\n",
    "\n",
    "# # Print the extracted Hindi words\n",
    "# print(hindi_words_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8PhdW5b4FqHf"
   },
   "outputs": [],
   "source": [
    "# Array which will store the corrected unicode corpus\n",
    "corrected_hindi_unicode = []\n",
    "\n",
    "def unicode_corrector(word):\n",
    "    n = len(word)\n",
    "    counter=0\n",
    "    res= []\n",
    "    for i in word:\n",
    "        counter+=1\n",
    "\n",
    "        # vowel\n",
    "        if(i in hindi_vowels):\n",
    "            res.append(i)\n",
    "\n",
    "        # matra or halanth\n",
    "        elif(i=='्' or (i in hindi_vowel_matras)): continue\n",
    "\n",
    "        #consonant followed by maatra\n",
    "        elif(counter != n and ((word[counter] in hindi_matras))):\n",
    "            res.append(i+'्')\n",
    "            res.append(hindi_vowel_matras[word[counter]])\n",
    "\n",
    "        #consonant followed by halanth\n",
    "        elif(counter != n and ((word[counter]=='्'))):\n",
    "            res.append(i+'्')\n",
    "\n",
    "        #consonant followed by consonant or nothing\n",
    "        else:\n",
    "            res.append(i+'्')\n",
    "            res.append('अ')\n",
    "    return res\n",
    "\n",
    "def driver_fun():\n",
    "    for word in hindi_words_unicode:\n",
    "        corrected_hindi_unicode.append(unicode_corrector(word))\n",
    "\n",
    "driver_fun()\n",
    "#print(corrected_hindi_unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQLB60gTr8R3"
   },
   "source": [
    "**QUESTION 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2ixF60HCsAg7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['श्', 'इ', 'व्', 'अ']\n"
     ]
    }
   ],
   "source": [
    "#TASK1: Find characters of each word in corpus\n",
    "\n",
    "# for word in corrected_hindi_unicode:\n",
    "#     print(word)\n",
    "word=\"शिव\"\n",
    "print(unicode_corrector(word))\n",
    "#this is because the corrected_hindi_unicode contains all words in format of characters separated by commas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9iArGrJStTZU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['शि', 'व']\n"
     ]
    }
   ],
   "source": [
    "#TASK 2: Find syllables of each word in corpus\n",
    "\n",
    "\n",
    "def generate_syllable(word):\n",
    "    counter=0\n",
    "    res= []\n",
    "    for i in word:\n",
    "        n = len(word)\n",
    "        counter+=1\n",
    "\n",
    "        if(counter-2>=0 and word[counter-2]=='्'): continue\n",
    "\n",
    "        # vowel\n",
    "        elif(i in hindi_vowels):\n",
    "            res.append(i)\n",
    "\n",
    "        # matra or halanth\n",
    "        elif(i=='्' or (i in hindi_vowel_matras)): continue\n",
    "\n",
    "        #consonant followed by maatra\n",
    "        elif(counter != n and((word[counter] in hindi_matras))):\n",
    "            res.append(i+word[counter])\n",
    "\n",
    "        #consonant followed by halanth\n",
    "        elif(counter != n and ((word[counter]=='्'))):\n",
    "            temp=\"\"\n",
    "            temp+=i+'्'\n",
    "            if(counter+1!=n):\n",
    "              temp+=word[counter+1]\n",
    "            if(counter+2<len(word) and (word[counter+2] in hindi_matras)):\n",
    "              temp+=word[counter+2]\n",
    "            res.append(temp)\n",
    "\n",
    "        #consonant followed by consonant or nothing\n",
    "        else:\n",
    "            res.append(i)\n",
    "    return res\n",
    "word=\"शिव\"\n",
    "print(generate_syllable(word))\n",
    "# for word in hindi_words_unicode:\n",
    "  #  print(generate_syllable(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEJq8kpwKHMZ",
    "outputId": "fb300fa7-1f84-49b4-db58-7c11676e6107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 6920186\n",
      "आ -> 2880591\n",
      "ए -> 2252786\n",
      "क् -> 2154491\n",
      "र् -> 2042130\n",
      "ई -> 1400159\n",
      "इ -> 1381197\n",
      "न् -> 1292346\n",
      "स् -> 1243319\n",
      "ह् -> 1111306\n",
      "म् -> 1025067\n",
      "त् -> 947386\n",
      "ल् -> 871027\n",
      "ओ -> 854867\n",
      "प् -> 763169\n",
      "य् -> 725955\n",
      "व् -> 601764\n",
      "द् -> 594358\n",
      "उ -> 565021\n",
      "ज् -> 522443\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 1153504\n",
      "अर् -> 753989\n",
      "क्अ -> 590665\n",
      "स्अ -> 557327\n",
      "न्अ -> 502259\n",
      "अन् -> 420021\n",
      "क्ए -> 405007\n",
      "प्अ -> 386770\n",
      "अह् -> 383763\n",
      "आर् -> 361905\n",
      "त्अ -> 351094\n",
      "अक् -> 347094\n",
      "म्अ -> 346094\n",
      "अत् -> 332923\n",
      "न्ए -> 321399\n",
      "ल्अ -> 316189\n",
      "क्आ -> 310409\n",
      "ह्ऐ -> 295332\n",
      "म्ए -> 293871\n",
      "य्आ -> 288250\n"
     ]
    }
   ],
   "source": [
    "#TASK 3: Find unigram and bigram frequencies for characters\n",
    "from collections import defaultdict\n",
    "\n",
    "# Counting the frequency of unigram characters\n",
    "map1 = defaultdict(int)\n",
    "\n",
    "for iter in corrected_hindi_unicode:\n",
    "    for element in iter:\n",
    "        map1[element] += 1\n",
    "\n",
    "print(\"Top 20 frequent unigram characters:\")\n",
    "unigram_sorted = sorted(map1.items(), key=lambda x: x[1], reverse=True)\n",
    "for element, count in unigram_sorted[:min(20, len(unigram_sorted))]:\n",
    "    print(element, \"->\", count)\n",
    "\n",
    "\n",
    "# Counting the frequency of bigram characters\n",
    "\n",
    "map2 = defaultdict(int)\n",
    "\n",
    "for word in corrected_hindi_unicode:\n",
    "    # Iterate over each pair of characters in the row\n",
    "    for i in range(len(word) - 1):\n",
    "        # Extract the current character and the next character to form a bigram\n",
    "        bigram = word[i] + word[i+1]\n",
    "        # Increment the count of the bigram\n",
    "        map2[bigram] += 1\n",
    "\n",
    "# Sort the bigram occurrences map by values in descending order\n",
    "bigram_sorted = sorted(map2.items(), key=lambda x: x[1], reverse=True)\n",
    "print()\n",
    "print(\"Top 20 frequent bigram characters:\")\n",
    "for i in range(min(20, len(bigram_sorted))):\n",
    "    print(bigram_sorted[i][0], \"->\", bigram_sorted[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQrh2Qc7NgTK",
    "outputId": "5bd101cd-9c56-401d-ac43-0a8548091434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 990762\n",
      "क -> 579573\n",
      "स -> 531782\n",
      "न -> 492056\n",
      "के -> 402954\n",
      "प -> 373338\n",
      "ने -> 320574\n",
      "म -> 317245\n",
      "ल -> 312545\n",
      "त -> 306703\n",
      "का -> 304125\n",
      "है -> 295156\n",
      "मे -> 290527\n",
      "ए -> 280108\n",
      "ह -> 276252\n",
      "अ -> 246636\n",
      "ब -> 233066\n",
      "की -> 232705\n",
      "ग -> 219326\n",
      "या -> 217584\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 156582\n",
      "और -> 115600\n",
      "पर -> 100124\n",
      "इस -> 82791\n",
      "लिए -> 53935\n",
      "एक -> 53930\n",
      "नही -> 49178\n",
      "अप -> 45001\n",
      "कार -> 38679\n",
      "किया -> 37023\n",
      "रने -> 34418\n",
      "कहा -> 32562\n",
      "यह -> 31206\n",
      "सर -> 30623\n",
      "गया -> 30208\n",
      "उन -> 28818\n",
      "आप -> 28665\n",
      "साथ -> 27701\n",
      "बाद -> 27352\n",
      "सके -> 27266\n"
     ]
    }
   ],
   "source": [
    "#TASK 4: Find unigram and bigram frequencies for syllables\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#array to store all syllables\n",
    "syl = []\n",
    "for word in hindi_words_unicode:\n",
    "  syl.append(generate_syllable(word))\n",
    "\n",
    "# Counting the frequency of unigram characters\n",
    "map1 = defaultdict(int)\n",
    "\n",
    "for iter in syl:\n",
    "    for element in iter:\n",
    "        map1[element] += 1\n",
    "\n",
    "# Top 20 frequent unigram syllables\n",
    "print(\"First 20 most occurring unigram syllables:\")\n",
    "unigram_sorted = sorted(map1.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(min(20, len(unigram_sorted))):\n",
    "    print(unigram_sorted[i][0], \"->\", unigram_sorted[i][1])\n",
    "\n",
    "\n",
    "map2 = defaultdict(int)\n",
    "\n",
    "for word in syl:\n",
    "    # Iterate over each pair of characters in the row\n",
    "    for i in range(len(word) - 1):\n",
    "        # Extract the current character and the next character to form a bigram\n",
    "        bigram = word[i] + word[i+1]\n",
    "        # Increment the count of the bigram\n",
    "        map2[bigram] += 1\n",
    "\n",
    "# Sort the bigram occurrences map by values in descending order\n",
    "bigram_sorted = sorted(map2.items(), key=lambda x: x[1], reverse=True)\n",
    "# Top 20 frequent bigram syllables\n",
    "print()\n",
    "print(\"First 20 most occurring bigram syllables:\")\n",
    "for i in range(min(20, len(bigram_sorted))):\n",
    "    print(bigram_sorted[i][0], \"->\", bigram_sorted[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T3yKIxUWlwI"
   },
   "source": [
    "**QUESTION 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASIO66B-5IBe"
   },
   "source": [
    "UNIGRAM TOKENIZER- VOCAB SIZE:1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGfn9Y_o38k-",
    "outputId": "c838487e-8608-423e-d2f0-ddfc86839323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\neelu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u5KHegm7Wst_"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train(input=\"hi_100_up.txt\", \n",
    "                               model_prefix=\"unigram_model_1k\", \n",
    "                               vocab_size=1000, \n",
    "                               model_type='unigram', \n",
    "                               max_sentence_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ERWbgIq-uhwB"
   },
   "outputs": [],
   "source": [
    "# Load the trained SentencePiece model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"unigram_model_1k.model\")\n",
    "\n",
    "# Define the input file path\n",
    "input_file = \"hi_100_up.txt\"\n",
    "\n",
    "# Open the input file and read its contents\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = sp.encode(content, out_type=str)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = \"tokenized_output_1k.txt\"\n",
    "\n",
    "# Write the tokenized output to the output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(tokens))\n",
    "\n",
    "# # Define the file path\n",
    "# file_path = \"tokenized_output_1k.txt\"\n",
    "\n",
    "# # Open the file and read its contents\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     # Iterate over each line in the file\n",
    "#     for line in file:\n",
    "#         # Split the line into words\n",
    "#         words = line.split()\n",
    "#         # Print each word on a separate line\n",
    "#         for word in words:\n",
    "#             print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crm-Ttf65Tyw"
   },
   "source": [
    "UNICODE CORRECTION ON TOKENIZED FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oJETV8g35ueY"
   },
   "outputs": [],
   "source": [
    "# Array which will store the corrected tokens\n",
    "corrected_tokens_unigram_1k = []\n",
    "\n",
    "def token_unicode_corrector(word):\n",
    "    n = len(word)\n",
    "    counter=0\n",
    "    res= []\n",
    "    if(n==1):\n",
    "      if(word=='्' or (word in hindi_vowel_matras)):\n",
    "        res.append(word)\n",
    "        return res\n",
    "\n",
    "    if(word[0] in hindi_vowel_matras or word[0]=='्'):\n",
    "          res.append(word[0])\n",
    "\n",
    "    for i in word:\n",
    "        counter+=1\n",
    "\n",
    "        # underscore\n",
    "        if(i=='▁'): continue\n",
    "\n",
    "        # vowel\n",
    "        elif(i in hindi_vowels):\n",
    "            res.append(i)\n",
    "\n",
    "        # matra or halanth\n",
    "        elif(i=='्' or (i in hindi_vowel_matras)): continue\n",
    "\n",
    "        #consonant followed by maatra\n",
    "        elif(counter != n and ((word[counter] in hindi_matras))):\n",
    "            res.append(i+'्')\n",
    "            res.append(hindi_vowel_matras[word[counter]])\n",
    "\n",
    "        #consonant followed by halanth\n",
    "        elif(counter != n and ((word[counter]=='्'))):\n",
    "            res.append(i+'्')\n",
    "\n",
    "        #consonant followed by consonant or nothing\n",
    "        else:\n",
    "            res.append(i+'्')\n",
    "            res.append('अ')\n",
    "    return res\n",
    "\n",
    "with open(\"tokenized_output_1k.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content\n",
    "    content = file.read()\n",
    "    # Tokenize the content\n",
    "    tokens = content.split()  # Assuming tokens are separated by whitespace\n",
    "    # Correct the tokens and store them in the array\n",
    "    for token in tokens:\n",
    "        corrected_tokens = token_unicode_corrector(token)\n",
    "        corrected_tokens_unigram_1k.append(corrected_tokens)\n",
    "\n",
    "# print(corrected_tokens_unigram_1k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uwIqStI1utkI"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_token_syllable(word):\n",
    "    counter=0\n",
    "    res= []\n",
    "    for i in word:\n",
    "        n = len(word)\n",
    "        counter+=1\n",
    "\n",
    "        if(counter-2>=0 and word[counter-2]=='्'): continue\n",
    "\n",
    "        #underscore or purnaviram\n",
    "        elif(i=='▁' or i=='।'): continue;\n",
    "\n",
    "        # vowel\n",
    "        elif(i in hindi_vowels):\n",
    "            res.append(i)\n",
    "\n",
    "        # matra or halanth\n",
    "        elif(i=='्' or (i in hindi_vowel_matras)): continue\n",
    "\n",
    "        #consonant followed by maatra\n",
    "        elif(counter != n and((word[counter] in hindi_matras))):\n",
    "            res.append(i+word[counter])\n",
    "\n",
    "        #consonant followed by halanth\n",
    "        elif(counter != n and ((word[counter]=='्'))):\n",
    "            temp=\"\"\n",
    "            if(counter+1<n):\n",
    "              temp+=i+'्'+word[counter+1]\n",
    "              if(counter+2!=n and (word[counter+2] in hindi_matras)):\n",
    "                temp+=word[counter+2]\n",
    "            res.append(temp)\n",
    "\n",
    "        #consonant followed by consonant or nothing\n",
    "        else:\n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "# for word in corrected_tokens_unigram_1k:\n",
    "#    print(generate_token_syllable(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d9s7QowE-_5"
   },
   "source": [
    "FREQUENCY COUNTER FUNCTION FOR CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_BbC362iUzl3"
   },
   "outputs": [],
   "source": [
    "## Counting the characters in corrected Tokens\n",
    "\n",
    "#Find unigram and bigram frequencies for characters\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def freq_module_char(token):\n",
    "  # Counting the frequency of unigram characters\n",
    "  map1 = defaultdict(int)\n",
    "\n",
    "  for iter in token:\n",
    "      for element in iter:\n",
    "          map1[element] += 1\n",
    "\n",
    "  print(\"Top 20 frequent unigram characters:\")\n",
    "  unigram_sorted = sorted(map1.items(), key=lambda x: x[1], reverse=True)\n",
    "  for element, count in unigram_sorted[:min(20, len(unigram_sorted))]:\n",
    "      print(element, \"->\", count)\n",
    "\n",
    "\n",
    "  # Counting the frequency of bigram characters\n",
    "\n",
    "  map2 = defaultdict(int)\n",
    "\n",
    "  for word in token:\n",
    "      # Iterate over each pair of characters in the row\n",
    "      for i in range(len(word) - 1):\n",
    "          # Extract the current character and the next character to form a bigram\n",
    "          bigram = word[i] + word[i+1]\n",
    "          # Increment the count of the bigram\n",
    "          map2[bigram] += 1\n",
    "\n",
    "  # Sort the bigram occurrences map by values in descending order\n",
    "  bigram_sorted = sorted(map2.items(), key=lambda x: x[1], reverse=True)\n",
    "  print()\n",
    "  print(\"Top 20 frequent bigram characters:\")\n",
    "  for i in range(min(20, len(bigram_sorted))):\n",
    "      print(bigram_sorted[i][0], \"->\", bigram_sorted[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S0eZd1qGpas"
   },
   "source": [
    "FREQUENCY COUNTER FUNCTION FOR SYLLABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ixCm-igzjGX5"
   },
   "outputs": [],
   "source": [
    "#TASK 4: Find unigram and bigram frequencies for syllables\n",
    "\n",
    "from collections import defaultdict\n",
    "def freq_module_syllable(token_string):\n",
    "  tokens = []\n",
    "  tokens = [char for char in token_string]\n",
    "  #array to store all syllables\n",
    "  syl = []\n",
    "  for word in tokens:\n",
    "    syl.append(generate_token_syllable(word))\n",
    "\n",
    "  # Counting the frequency of unigram characters\n",
    "  map1 = defaultdict(int)\n",
    "\n",
    "  for iter in syl:\n",
    "      for element in iter:\n",
    "          map1[element] += 1\n",
    "\n",
    "  # Top 20 frequent unigram syllables\n",
    "  print(\"First 20 most occurring unigram syllables:\")\n",
    "  unigram_sorted = sorted(map1.items(), key=lambda x: x[1], reverse=True)\n",
    "  for i in range(min(20, len(unigram_sorted))):\n",
    "      print(unigram_sorted[i][0], \"->\", unigram_sorted[i][1])\n",
    "\n",
    "\n",
    "  map2 = defaultdict(int)\n",
    "\n",
    "  for word in syl:\n",
    "      # Iterate over each pair of characters in the row\n",
    "      for i in range(len(word) - 1):\n",
    "          # Extract the current character and the next character to form a bigram\n",
    "          bigram = word[i] + word[i+1]\n",
    "          # Increment the count of the bigram\n",
    "          map2[bigram] += 1\n",
    "\n",
    "  # Sort the bigram occurrences map by values in descending order\n",
    "  bigram_sorted = sorted(map2.items(), key=lambda x: x[1], reverse=True)\n",
    "  # Top 20 frequent bigram syllables\n",
    "  print()\n",
    "  print(\"First 20 most occurring bigram syllables:\")\n",
    "  for i in range(min(20, len(bigram_sorted))):\n",
    "      print(bigram_sorted[i][0], \"->\", bigram_sorted[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwrBDTk5Htao"
   },
   "source": [
    "CONVERTING TOKENS IN FILE TO TOKENS IN ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PBN5Q0YLacZV"
   },
   "outputs": [],
   "source": [
    "## Converting tokens in file to tokens in array\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"tokenized_output_1k.txt\"\n",
    "\n",
    "# Initialize an empty array to store tokens\n",
    "tokens = []\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "    # Split the content by spaces to extract tokens\n",
    "    for char in garbage:\n",
    "        content = content.replace(char, '')\n",
    "    tokens = content.split()\n",
    "\n",
    "\n",
    "for idx, word in enumerate(tokens):\n",
    "    # Replace the character \"▁\" with an empty string in the word\n",
    "    tokens[idx] = word.replace(\"▁\", \"\")\n",
    "\n",
    "\n",
    "# Print the tokens array\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQbE9g59JfA6"
   },
   "source": [
    "FREQUENCY COUNTER FUNCTION FOR TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ltV5RYEBh4Bs"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def freq_module_strings(token_array):\n",
    "\n",
    "  # Initialize a defaultdict with int as the default factory\n",
    "  map1 = defaultdict(int)\n",
    "\n",
    "  # Iterate over each string in the array and update the counts in the defaultdict\n",
    "  for word in token_array:\n",
    "      map1[word] += 1\n",
    "\n",
    "  sorted_map1 = sorted(map1.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  # Print the top 20 unigram frequencies\n",
    "  print(\"Top 20 unigram frequencies of tokens:\")\n",
    "  for word, count in sorted_map1[:20]:\n",
    "      print(f\"{word}: {count}\")\n",
    "\n",
    "  map2 = defaultdict(int)\n",
    "\n",
    "  # Iterate over each pair of consecutive strings in the token_array list and update the counts in the defaultdict\n",
    "  for i in range(len(token_array) - 1):\n",
    "      bigram = (token_array[i], token_array[i + 1])\n",
    "      map2[bigram] += 1\n",
    "\n",
    "  # Sort the dictionary by values in descending order\n",
    "  sorted_map2 = sorted(map2.items(), key=lambda x: x[1], reverse=True)\n",
    "  print()\n",
    "  # Print the top 20 bigram frequencies\n",
    "  print(\"Top 20 bigram frequencies of tokens:\")\n",
    "  for bigram, count in sorted_map2[:20]:\n",
    "      print(f\"{bigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYuonXoFqvMx",
    "outputId": "d376a3a1-e3ad-47d0-90f4-6f97704ca814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 11254642\n",
      "आ -> 2427706\n",
      "क् -> 2220998\n",
      "र् -> 2115451\n",
      "ए -> 2020934\n",
      "न् -> 1334322\n",
      "स् -> 1283598\n",
      "ई -> 1215677\n",
      "ह् -> 1133109\n",
      "म् -> 1053158\n",
      "इ -> 1028832\n",
      "त् -> 980008\n",
      "ल् -> 919858\n",
      "प् -> 805828\n",
      "य् -> 753163\n",
      "व् -> 624678\n",
      "ओ -> 617876\n",
      "द् -> 607586\n",
      "ा -> 563192\n",
      "ज् -> 556551\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 1524435\n",
      "क्अ -> 749364\n",
      "स्अ -> 680390\n",
      "न्अ -> 663283\n",
      "म्अ -> 523555\n",
      "प्अ -> 508313\n",
      "त्अ -> 486897\n",
      "अर् -> 478148\n",
      "ल्अ -> 471833\n",
      "क्ए -> 399571\n",
      "ह्अ -> 361069\n",
      "य्अ -> 360855\n",
      "अह् -> 345222\n",
      "ब्अ -> 326627\n",
      "न्ए -> 322575\n",
      "ज्अ -> 321746\n",
      "ग्अ -> 316785\n",
      "व्अ -> 312753\n",
      "ह्ऐ -> 296118\n",
      "द्अ -> 290741\n"
     ]
    }
   ],
   "source": [
    "#counting frequencies of characters\n",
    "\n",
    "freq_module_char(corrected_tokens_unigram_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wv5y8f6Lo8cR",
    "outputId": "6822cf40-d6b6-4aad-db97-0e2c6d0e68c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 1276493\n",
      "क -> 729607\n",
      "न -> 654993\n",
      "स -> 645095\n",
      "प -> 495740\n",
      "म -> 478027\n",
      "ल -> 460229\n",
      "त -> 424525\n",
      "के -> 399571\n",
      "ह -> 350828\n",
      "ने -> 322575\n",
      "ब -> 322181\n",
      "ग -> 309203\n",
      "ज -> 308789\n",
      "है -> 296118\n",
      "का -> 289964\n",
      "ए -> 286303\n",
      "द -> 271134\n",
      "मे -> 267619\n",
      "व -> 261346\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 171970\n",
      "और -> 115376\n",
      "पर -> 112545\n",
      "इस -> 92849\n",
      "एक -> 58947\n",
      "लिए -> 53135\n",
      "ड़ -> 52770\n",
      "नही -> 47279\n",
      "कार -> 46869\n",
      "अप -> 39579\n",
      "सम -> 37111\n",
      "किया -> 36573\n",
      "यह -> 35278\n",
      "कहा -> 32993\n",
      "देश -> 30633\n",
      "गया -> 30203\n",
      "रने -> 29867\n",
      "उन -> 29729\n",
      "आप -> 29430\n",
      "उस -> 27954\n"
     ]
    }
   ],
   "source": [
    "#counting frequencies of syllables\n",
    "\n",
    "freq_module_syllable(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpzm82iPowMZ",
    "outputId": "7115d8b7-bd82-41ff-b99a-86fd8ec6af1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "ा: 493831\n",
      "र: 447172\n",
      "के: 348894\n",
      "न: 327570\n",
      "ल: 271702\n",
      "म: 271534\n",
      "क: 243068\n",
      "में: 240292\n",
      "ी: 229884\n",
      "की: 217765\n",
      "है: 215661\n",
      "ने: 215136\n",
      "स: 208675\n",
      "त: 201590\n",
      "े: 190356\n",
      "प: 187405\n",
      "ज: 177278\n",
      "से: 173321\n",
      "व: 164951\n",
      "को: 159958\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('के', 'लिए'): 43622\n",
      "('ा', 'र'): 32840\n",
      "('ा', 'न'): 26994\n",
      "('है', 'कि'): 25524\n",
      "('ों', 'के'): 23499\n",
      "('म', 'ा'): 21569\n",
      "('ों', 'में'): 20877\n",
      "('र', 'ा'): 19779\n",
      "('ध', 'ा'): 19681\n",
      "('ों', 'को'): 18691\n",
      "('के', 'साथ'): 18485\n",
      "('स', 'ा'): 18428\n",
      "('ने', 'के'): 17316\n",
      "('ा', 'म'): 17210\n",
      "('ज', 'ा'): 17072\n",
      "('ज', 'न'): 16180\n",
      "('ता', 'है'): 16170\n",
      "('कहा', 'कि'): 16108\n",
      "('ते', 'हैं'): 15779\n",
      "('र', 'ी'): 15637\n"
     ]
    }
   ],
   "source": [
    "#counting frequencies of tokens\n",
    "\n",
    "freq_module_strings(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSdILwF6rAz-"
   },
   "source": [
    "FINDING FREQUENCIES FOR VOCAB SIZE: 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jnmtTVX8zq8b"
   },
   "outputs": [],
   "source": [
    "#Training unigram model on vocab size=2000\n",
    "\n",
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train(input=\"hi_100_up.txt\", model_prefix=\"unigram_model_2k\", vocab_size=2000, model_type='unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "T1bIKXAI4YCR"
   },
   "outputs": [],
   "source": [
    "# Load the trained SentencePiece model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"unigram_model_2k.model\")\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"hi_100_up.txt\"\n",
    "output_file = \"tokenized_output_2k.txt\"\n",
    "\n",
    "# Open the input file and read its contents\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = sp.encode(text, out_type=str)\n",
    "\n",
    "# Write the tokenized output to the output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RE3jELJmVW_o"
   },
   "outputs": [],
   "source": [
    "# Array which will store the corrected tokens\n",
    "corrected_tokens_unigram_2k = []\n",
    "\n",
    "tokens2=[]\n",
    "with open(\"tokenized_output_2k.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content\n",
    "    content = file.read()\n",
    "    # Tokenize the content\n",
    "    tokens2 = content.split()  # Assuming tokens are separated by whitespace\n",
    "    # Correct the tokens and store them in the array\n",
    "    for token in tokens2:\n",
    "        corrected_tokens = token_unicode_corrector(token)\n",
    "        corrected_tokens_unigram_2k.append(corrected_tokens)\n",
    "\n",
    "# print(corrected_tokens_unigram_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbCKBNLJrFZk",
    "outputId": "890b95ab-357e-4527-94ba-ab4b54d17079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 10138276\n",
      "आ -> 2768907\n",
      "क् -> 2220998\n",
      "ए -> 2155987\n",
      "र् -> 2115451\n",
      "न् -> 1334322\n",
      "स् -> 1283598\n",
      "ई -> 1280310\n",
      "इ -> 1176572\n",
      "ह् -> 1133109\n",
      "म् -> 1053158\n",
      "त् -> 980008\n",
      "ल् -> 919858\n",
      "प् -> 805828\n",
      "य् -> 753163\n",
      "ओ -> 716506\n",
      "व् -> 624678\n",
      "द् -> 607586\n",
      "ज् -> 556551\n",
      "उ -> 526236\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 1388650\n",
      "क्अ -> 692591\n",
      "स्अ -> 634812\n",
      "अर् -> 629744\n",
      "न्अ -> 614962\n",
      "प्अ -> 460969\n",
      "त्अ -> 438142\n",
      "ल्अ -> 430650\n",
      "म्अ -> 419151\n",
      "क्ए -> 400927\n",
      "अह् -> 356669\n",
      "ह्अ -> 327526\n",
      "य्अ -> 324617\n",
      "न्ए -> 322155\n",
      "क्आ -> 306800\n",
      "ब्अ -> 297007\n",
      "ह्ऐ -> 296102\n",
      "आर् -> 295443\n",
      "म्ए -> 291083\n",
      "य्आ -> 289024\n"
     ]
    }
   ],
   "source": [
    "#counting frequencies of characters\n",
    "\n",
    "freq_module_char(corrected_tokens_unigram_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kgr-RujzrTgL",
    "outputId": "77ed3d17-0558-4973-f432-a0336b0a8542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 1156839\n",
      "क -> 675021\n",
      "न -> 603462\n",
      "स -> 601233\n",
      "प -> 439845\n",
      "ल -> 416613\n",
      "के -> 400228\n",
      "म -> 378167\n",
      "त -> 372677\n",
      "ने -> 322155\n",
      "ह -> 319756\n",
      "का -> 305866\n",
      "है -> 296102\n",
      "ब -> 291000\n",
      "मे -> 288978\n",
      "ए -> 286303\n",
      "ग -> 270871\n",
      "ज -> 264638\n",
      "अ -> 253182\n",
      "व -> 243464\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 171135\n",
      "और -> 115376\n",
      "पर -> 112130\n",
      "इस -> 84414\n",
      "एक -> 57179\n",
      "लिए -> 53135\n",
      "कार -> 49355\n",
      "नही -> 49103\n",
      "ड़ -> 48661\n",
      "अप -> 44765\n",
      "किया -> 36573\n",
      "यह -> 34020\n",
      "कहा -> 32991\n",
      "देश -> 30563\n",
      "रने -> 30559\n",
      "गया -> 30203\n",
      "आप -> 28672\n",
      "उन -> 28521\n",
      "उस -> 28345\n",
      "साथ -> 27696\n"
     ]
    }
   ],
   "source": [
    "#counting frequencies of syllables\n",
    "\n",
    "freq_module_syllable(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cb6Otxs8w49P"
   },
   "outputs": [],
   "source": [
    "## Converting tokens in file to tokens in array\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"tokenized_output_2k.txt\"\n",
    "\n",
    "# Initialize an empty array to store tokens\n",
    "tokens2 = []\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "    # Split the content by spaces to extract tokens\n",
    "    for char in garbage:\n",
    "        content = content.replace(char, '')\n",
    "    tokens2 = content.split()\n",
    "\n",
    "\n",
    "for idx, word in enumerate(tokens2):\n",
    "    # Replace the character \"▁\" with an empty string in the word\n",
    "    tokens2[idx] = word.replace(\"▁\", \"\")\n",
    "\n",
    "\n",
    "# Print the tokens array (optional)\n",
    "# print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGOj9TuKv12L",
    "outputId": "60e7c943-5d58-4f39-9048-827c093fe1a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "के: 336021\n",
      "में: 240292\n",
      "है: 215652\n",
      "की: 206996\n",
      "न: 177273\n",
      "ने: 170640\n",
      "ी: 168064\n",
      "को: 161734\n",
      "से: 159010\n",
      "र: 158988\n",
      "का: 157826\n",
      "ल: 157351\n",
      "क: 138034\n",
      "म: 127023\n",
      ": 124511\n",
      "स: 123495\n",
      "और: 115376\n",
      "ा: 114518\n",
      "पर: 110185\n",
      "ों: 109878\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('के', 'लिए'): 43622\n",
      "('है', 'कि'): 25511\n",
      "('ों', 'के'): 19428\n",
      "('के', 'साथ'): 18476\n",
      "('ों', 'में'): 17906\n",
      "('कहा', 'कि'): 16109\n",
      "('ों', 'को'): 14967\n",
      "('के', 'बाद'): 14510\n",
      "('ों', 'की'): 12683\n",
      "('ने', 'कहा'): 12227\n",
      "('रहा', 'है'): 12023\n",
      "('ने', 'के'): 11704\n",
      "('है', 'और'): 11214\n",
      "('गया', 'है'): 11060\n",
      "('रहे', 'हैं'): 10179\n",
      "('करने', 'के'): 8848\n",
      "('है', ''): 8797\n",
      "('रही', 'है'): 8754\n",
      "('', ''): 8219\n",
      "('ता', 'है'): 8154\n"
     ]
    }
   ],
   "source": [
    "#counting frequencies of tokens\n",
    "\n",
    "freq_module_strings(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr4i0WXSg30R"
   },
   "source": [
    "**BPE TOKENIZER, VOCAB SIZE=1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "utSwVILvg9HD"
   },
   "outputs": [],
   "source": [
    "#Training BPE model on vocab size=1000\n",
    "\n",
    "spm.SentencePieceTrainer.train(input=\"hi_100_up.txt\", model_prefix=\"bpe_model_1k\", vocab_size=1000, model_type='bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9xJjGtKnhwtN"
   },
   "outputs": [],
   "source": [
    "# Load the trained SentencePiece model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"bpe_model_1k.model\")\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"hi_100_up.txt\"\n",
    "output_file = \"tokenized_bpe_output_1k.txt\"\n",
    "\n",
    "# Open the input file and read its contents\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = sp.encode(text, out_type=str)\n",
    "\n",
    "# Write the tokenized output to the output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dES0Ndq4oOy8"
   },
   "source": [
    "**BPE TOKENIZER, VOCAB SIZE=2000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\neelu\\anaconda3\\lib\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1HGuQJS2oT1w"
   },
   "outputs": [],
   "source": [
    "#Training BPE model on vocab size=2000\n",
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train(input=\"hi_100_up.txt\", model_prefix=\"bpe_model_2k\", vocab_size=2000, model_type='bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2SoOUoTFpL_Z"
   },
   "outputs": [],
   "source": [
    "# Load the trained SentencePiece model\n",
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"bpe_model_2k.model\")\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"hi_100_up.txt\"\n",
    "output_file = \"tokenized_bpe_output_2k.txt\"\n",
    "\n",
    "# Open the input file and read its contents\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens2 = sp.encode(text, out_type=str)\n",
    "\n",
    "# Write the tokenized output to the output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(tokens2))\n",
    "\n",
    "\n",
    "# file_path = \"/content/tokenized_bpe_output_1k.txt\"\n",
    "\n",
    "# # Open the file and read its contents\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     # Iterate over each line in the file\n",
    "#     for line in file:\n",
    "#         # Split the line into words\n",
    "#         words = line.split()\n",
    "#         # Print each word on a separate line\n",
    "#         for word in words:\n",
    "#             print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWHsaGRRlFZg"
   },
   "source": [
    "UNICODE CORRECTION ON TOKENIZED FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lwBjfq6_lHVV"
   },
   "outputs": [],
   "source": [
    "# Array which will store the corrected tokens\n",
    "corrected_tokens_bpe_1k = []\n",
    "\n",
    "with open(\"tokenized_bpe_output_1k.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content\n",
    "    content = file.read()\n",
    "    # Tokenize the content\n",
    "    tokens = content.split()  # Assuming tokens are separated by whitespace\n",
    "    # print(tokens)\n",
    "    # Correct the tokens and store them in the array\n",
    "    for token in tokens:\n",
    "        corrected_tokens = token_unicode_corrector(token)\n",
    "        corrected_tokens_bpe_1k.append(corrected_tokens)\n",
    "\n",
    "#print(corrected_tokens_bpe_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wGlM3Qeopm1C"
   },
   "outputs": [],
   "source": [
    "# Array which will store the corrected tokens\n",
    "corrected_tokens_bpe_2k = []\n",
    "\n",
    "with open(\"tokenized_bpe_output_2k.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content\n",
    "    content = file.read()\n",
    "    # Tokenize the content\n",
    "    tokens2 = content.split()  # Assuming tokens are separated by whitespace\n",
    "    # Correct the tokens and store them in the array\n",
    "    for token in tokens2:\n",
    "        corrected_tokens = token_unicode_corrector(token)\n",
    "        corrected_tokens_bpe_2k.append(corrected_tokens)\n",
    "\n",
    "# print(corrected_tokens_bpe_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-ACW2VHgnQxY"
   },
   "outputs": [],
   "source": [
    "#cleaning\n",
    "import re\n",
    "# Read the contents of the text file\n",
    "with open('tokenized_bpe_output_1k.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Define a regular expression pattern to match English words\n",
    "english_pattern = re.compile(r'[a-zA-Z]+')\n",
    "\n",
    "# Iterate through each line in the corpus\n",
    "clean_corpus = []\n",
    "for line in corpus:\n",
    "    # Tokenize the line and remove English words\n",
    "    tokens = line.split()  # Assuming space-separated tokens\n",
    "    tokens = [token for token in tokens if not re.match(english_pattern, token)]\n",
    "    cleaned_line = ' '.join(tokens)\n",
    "    clean_corpus.append(cleaned_line)\n",
    "\n",
    "# Join the lines back into a single text\n",
    "clean_text = '\\n'.join(clean_corpus)\n",
    "\n",
    "# Print the updated content\n",
    "# print(clean_text)\n",
    "\n",
    "# Optionally, write the clean text back to a file\n",
    "with open('tokenized_bpe_output_1k.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(clean_text)\n",
    "\n",
    "\n",
    "\n",
    "# Converting tokens in file to tokens in array\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"tokenized_bpe_output_1k.txt\"\n",
    "\n",
    "# Initialize an empty array to store tokens\n",
    "tokens = []\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "    # Split the content by spaces to extract tokens\n",
    "    for char in garbage:\n",
    "        content = content.replace(char, '')\n",
    "    tokens = content.split()\n",
    "\n",
    "\n",
    "for idx, word in enumerate(tokens):\n",
    "    # Replace the character \"▁\" with an empty string in the word\n",
    "    tokens[idx] = word.replace(\"▁\", \"\")\n",
    "\n",
    "tokens = [word for word in tokens if word]\n",
    "\n",
    "# Remove empty strings and strings containing only whitespace\n",
    "tokens = [word.strip() for word in tokens if word.strip()]\n",
    "\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MEM3W2JKnv-a"
   },
   "outputs": [],
   "source": [
    "#cleaning\n",
    "import re\n",
    "# Read the contents of the text file\n",
    "with open('tokenized_bpe_output_2k.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Define a regular expression pattern to match English words\n",
    "english_pattern = re.compile(r'[a-zA-Z]+')\n",
    "\n",
    "# Iterate through each line in the corpus\n",
    "clean_corpus = []\n",
    "for line in corpus:\n",
    "    # Tokenize the line and remove English words\n",
    "    tokens = line.split()  # Assuming space-separated tokens\n",
    "    tokens = [token for token in tokens if not re.match(english_pattern, token)]\n",
    "    cleaned_line = ' '.join(tokens)\n",
    "    clean_corpus.append(cleaned_line)\n",
    "\n",
    "# Join the lines back into a single text\n",
    "clean_text = '\\n'.join(clean_corpus)\n",
    "\n",
    "# Print the updated content\n",
    "# print(clean_text)\n",
    "\n",
    "# Optionally, write the clean text back to a file\n",
    "with open('tokenized_bpe_output_2k.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(clean_text)\n",
    "\n",
    "\n",
    "# Converting tokens in file to tokens in array\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"tokenized_bpe_output_2k.txt\"\n",
    "\n",
    "# Initialize an empty array to store tokens\n",
    "tokens2 = []\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "    # Split the content by spaces to extract tokens\n",
    "    for char in garbage:\n",
    "        content = content.replace(char, '')\n",
    "    tokens2 = content.split()\n",
    "\n",
    "\n",
    "for idx, word in enumerate(tokens2):\n",
    "    # Replace the character \"▁\" with an empty string in the word\n",
    "    tokens2[idx] = word.replace(\"▁\", \"\")\n",
    "\n",
    "tokens2 = [word for word in tokens2 if word]\n",
    "\n",
    "# Remove empty strings and strings containing only whitespace\n",
    "tokens2 = [word.strip() for word in tokens2 if word.strip(\" \")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tAMymQAmQff"
   },
   "source": [
    "COUNTING FREQUENCIES, VOCAB SIZE=1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxiGsIXpnEVK",
    "outputId": "84c7fa27-451c-437f-846a-328eb0b05f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 11070320\n",
      "आ -> 2495295\n",
      "क् -> 2220998\n",
      "र् -> 2115451\n",
      "ए -> 2056601\n",
      "ई -> 1342158\n",
      "न् -> 1334322\n",
      "स् -> 1283598\n",
      "ह् -> 1133109\n",
      "म् -> 1053158\n",
      "त् -> 980008\n",
      "इ -> 941618\n",
      "ल् -> 919858\n",
      "प् -> 805828\n",
      "य् -> 753163\n",
      "ओ -> 636698\n",
      "व् -> 624678\n",
      "द् -> 607586\n",
      "ज् -> 556551\n",
      "ब् -> 524575\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 1442527\n",
      "क्अ -> 739120\n",
      "स्अ -> 644774\n",
      "न्अ -> 617238\n",
      "अर् -> 557198\n",
      "म्अ -> 523550\n",
      "प्अ -> 511988\n",
      "ल्अ -> 461635\n",
      "त्अ -> 452101\n",
      "क्ए -> 393577\n",
      "ह्अ -> 362677\n",
      "य्अ -> 347466\n",
      "ब्अ -> 334838\n",
      "ग्अ -> 331481\n",
      "न्ए -> 325947\n",
      "अह् -> 317337\n",
      "व्अ -> 314246\n",
      "ज्अ -> 301428\n",
      "ह्ऐ -> 296118\n",
      "य्आ -> 288173\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_tokens_bpe_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBuIEzkRp9Eb",
    "outputId": "4ce1320e-192f-4504-fee6-9d91c51fbe67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 1135723\n",
      "क -> 680035\n",
      "स -> 602255\n",
      "न -> 583950\n",
      "प -> 458638\n",
      "ल -> 415925\n",
      "म -> 407011\n",
      "के -> 402863\n",
      "त -> 368490\n",
      "ह -> 334846\n",
      "ने -> 325947\n",
      "ब -> 310272\n",
      "का -> 302692\n",
      "है -> 296118\n",
      "ग -> 293687\n",
      "ए -> 286303\n",
      "मे -> 285739\n",
      "ज -> 263527\n",
      "अ -> 253182\n",
      "व -> 252446\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 169576\n",
      "और -> 115365\n",
      "पर -> 107319\n",
      "इस -> 83160\n",
      "एक -> 54352\n",
      "लिए -> 53777\n",
      "कार -> 49903\n",
      "नही -> 49103\n",
      "अप -> 46073\n",
      "ड़ -> 43487\n",
      "किया -> 36546\n",
      "सम -> 35035\n",
      "सर -> 31429\n",
      "कहा -> 31235\n",
      "यह -> 31055\n",
      "गया -> 30203\n",
      "देश -> 29873\n",
      "रने -> 29856\n",
      "आप -> 29453\n",
      "तर -> 28358\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vHiF8t6rDjp",
    "outputId": "107c86ee-d99e-4eb5-cfb5-82778de20520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "के: 364425\n",
      "में: 252763\n",
      "न: 234688\n",
      "की: 227547\n",
      "क: 221778\n",
      "म: 219906\n",
      "है: 215519\n",
      "ने: 205149\n",
      "ल: 196225\n",
      "प: 195028\n",
      "त: 192529\n",
      "स: 180036\n",
      "से: 171974\n",
      "र: 171061\n",
      "को: 170947\n",
      "व: 169110\n",
      "ज: 167772\n",
      "का: 164069\n",
      "ब: 156623\n",
      "द: 154973\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('के', 'लिए'): 44391\n",
      "('है', 'कि'): 25769\n",
      "('के', 'साथ'): 18663\n",
      "('ों', 'के'): 18036\n",
      "('कहा', 'कि'): 16141\n",
      "('ों', 'में'): 16099\n",
      "('ते', 'हैं'): 15853\n",
      "('ने', 'के'): 15697\n",
      "('के', 'बाद'): 15556\n",
      "('ों', 'को'): 14294\n",
      "('ता', 'है'): 13225\n",
      "('ने', 'कहा'): 12400\n",
      "('रहा', 'है'): 12024\n",
      "('ों', 'की'): 11538\n",
      "('है', 'और'): 11317\n",
      "('गया', 'है'): 11060\n",
      "('रहे', 'हैं'): 10181\n",
      "('वार', 'को'): 9230\n",
      "('ने', 'की'): 9095\n",
      "('करने', 'के'): 8848\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQjHvtJyrNls"
   },
   "source": [
    "COUNTING FREQUENCIES, VOCAB SIZE=2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nULO3tSnrRXM",
    "outputId": "74817497-4772-433f-de26-5f0a1aab1cf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 10202458\n",
      "आ -> 2688032\n",
      "क् -> 2220998\n",
      "ए -> 2171626\n",
      "र् -> 2115451\n",
      "ई -> 1403945\n",
      "न् -> 1334322\n",
      "स् -> 1283598\n",
      "ह् -> 1133109\n",
      "इ -> 1103639\n",
      "म् -> 1053158\n",
      "त् -> 980008\n",
      "ल् -> 919858\n",
      "प् -> 805828\n",
      "य् -> 753163\n",
      "ओ -> 716010\n",
      "व् -> 624678\n",
      "द् -> 607586\n",
      "ज् -> 556551\n",
      "ब् -> 524575\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 1359960\n",
      "क्अ -> 689095\n",
      "अर् -> 635277\n",
      "स्अ -> 629310\n",
      "न्अ -> 589910\n",
      "प्अ -> 470352\n",
      "म्अ -> 453922\n",
      "ल्अ -> 426036\n",
      "त्अ -> 413073\n",
      "क्ए -> 402863\n",
      "अह् -> 349872\n",
      "ह्अ -> 337506\n",
      "न्ए -> 325947\n",
      "य्अ -> 325788\n",
      "ब्अ -> 310272\n",
      "क्आ -> 304294\n",
      "ह्ऐ -> 296118\n",
      "ग्अ -> 295416\n",
      "य्आ -> 291596\n",
      "आर् -> 289886\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_tokens_bpe_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9SSdY4-rRy_",
    "outputId": "eaa99909-1062-4484-f367-0afed560c838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 1135723\n",
      "क -> 680035\n",
      "स -> 602255\n",
      "न -> 583950\n",
      "प -> 458638\n",
      "ल -> 415925\n",
      "म -> 407011\n",
      "के -> 402863\n",
      "त -> 368490\n",
      "ह -> 334846\n",
      "ने -> 325947\n",
      "ब -> 310272\n",
      "का -> 302692\n",
      "है -> 296118\n",
      "ग -> 293687\n",
      "ए -> 286303\n",
      "मे -> 285739\n",
      "ज -> 263527\n",
      "अ -> 253182\n",
      "व -> 252446\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 169576\n",
      "और -> 115365\n",
      "पर -> 107319\n",
      "इस -> 83160\n",
      "एक -> 54352\n",
      "लिए -> 53777\n",
      "कार -> 49903\n",
      "नही -> 49103\n",
      "अप -> 46073\n",
      "ड़ -> 43487\n",
      "किया -> 36546\n",
      "सम -> 35035\n",
      "सर -> 31429\n",
      "कहा -> 31235\n",
      "यह -> 31055\n",
      "गया -> 30203\n",
      "देश -> 29873\n",
      "रने -> 29856\n",
      "आप -> 29453\n",
      "तर -> 28358\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4GWN4z9rSJC",
    "outputId": "11339ed6-7a53-4d01-89f2-2d208c117392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "के: 344221\n",
      "में: 245492\n",
      "है: 215519\n",
      "की: 214643\n",
      "ने: 178498\n",
      "को: 164636\n",
      "से: 161950\n",
      "का: 147960\n",
      "क: 131671\n",
      "न: 122821\n",
      "और: 115365\n",
      "म: 109222\n",
      "स: 108686\n",
      "पर: 105519\n",
      "प: 97698\n",
      "ल: 94387\n",
      "कि: 92992\n",
      "व: 91544\n",
      "त: 91188\n",
      "कर: 89709\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('के', 'लिए'): 43665\n",
      "('है', 'कि'): 25514\n",
      "('के', 'साथ'): 18478\n",
      "('कहा', 'कि'): 16132\n",
      "('के', 'बाद'): 14524\n",
      "('ों', 'में'): 12939\n",
      "('ों', 'के'): 12928\n",
      "('ने', 'कहा'): 12055\n",
      "('रहा', 'है'): 12024\n",
      "('ने', 'के'): 11871\n",
      "('है', 'और'): 11317\n",
      "('गया', 'है'): 11060\n",
      "('रहे', 'हैं'): 10181\n",
      "('ों', 'को'): 10098\n",
      "('ता', 'है'): 9988\n",
      "('करने', 'के'): 8848\n",
      "('रही', 'है'): 8754\n",
      "('ों', 'की'): 8241\n",
      "('ते', 'हैं'): 7862\n",
      "('जाता', 'है'): 7337\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvnJonbq-6F6"
   },
   "source": [
    "**mBERT TOKENIZER WITH MAX LENGTH=1000 AND 2000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "BAXIgter38lJ"
   },
   "outputs": [],
   "source": [
    "!pip install torch flax tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apvbE1zP38lJ"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274,
     "referenced_widgets": [
      "48ad886206ce4418a007f87630406cb0",
      "1d2bc99d54d14a7584dbcd8c0bc65ddd",
      "7cd9e8956fc846069834db97678be5ea",
      "55baca83487b4e348513ba429f0a9ecd",
      "1e6a096a8ac648f0aeb2cf71c8deffeb",
      "7487d9b800bc438a9365b2a99db92f8c",
      "f4bcff6d72b04623ad6c285f355f8202",
      "1c14cde1581441278e4a9ba4cad54412",
      "2f6bc8995cfc432c86eba609929b8c36",
      "96a128bc9a3c4611bfa544cee0f91ab7",
      "125dc81fa2944707bd081c39061249fb",
      "4934c43ec86d42f5a9769b9d5ce4aa30",
      "4f5fc6ff879e49cc873335cb7669ab8e",
      "844b1cdfe5184efcb6ba3ec8ff0b1e3e",
      "1a34784a3c0c46928a4f159d89537558",
      "fbb35283dcef4c42b179fa9af8d98bc5",
      "f3186f242a8e4e7abec36f8816e5a7bf",
      "ecb1550760714ef2b74ef05461bbfbf0",
      "bf47a7f141c5487a848aed5a74d3baf7",
      "dd9ac2286d134938be7b0fbccc4a0880",
      "b0707db3fa2c426d8a790ca9ce873ae0",
      "1685f8a4dee04d04b114d7e2498e0331",
      "075fed85f05c4d0abf24cbde352b2334",
      "2163800d8d1441f491f72e09c7fb3d59",
      "02428b05dea84a81ad7340c2b2bddcc8",
      "82335f07589347b48f88c046d43faaa3",
      "a09bfd47e33e4854a5cac70ff5616ab1",
      "fe19ff4e622f4a2ca7e5c3b0e46958cb",
      "fac61314219f49f1b0d1354be8c5f4cf",
      "1e96613a00844d459c0be0f754452c8a",
      "37e7170414b34c0192a24af4b17131cc",
      "49e215b472ab4ce3b072b5af13a59b49",
      "854e860c6ef34526afbf50c322514c2d",
      "e89781736dd2496094964e8a29790e2d",
      "6235a141661841b6a4b7d7a390738d85",
      "a8afb1efc784497a937b54917869cbc9",
      "de825535a35b4ba785d99c350577bf5c",
      "ce0f4ea95d94407398ddecfe2b048c34",
      "9d0f371b02244b608a8d4854ee6b1b71",
      "97ffefd8d81f42309585e8d1698a62bf",
      "00772505c6934c7c9852de01dfe79882",
      "57bbb86c5cbf42119ce241a76a0f968b",
      "1d120f1b36f84354a552d698c1570c91",
      "2710377e107e42ddb84d7f13be76fdb2"
     ]
    },
    "id": "hi0Bi3xO_1SJ",
    "outputId": "d5008d61-d9d6-4783-eed6-46fc3ec73a9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ad886206ce4418a007f87630406cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4934c43ec86d42f5a9769b9d5ce4aa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075fed85f05c4d0abf24cbde352b2334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89781736dd2496094964e8a29790e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer with maximum input length set to 1000\n",
    "tokenizer1 = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    max_length=1000,\n",
    "    do_basic_tokenize=False\n",
    ")\n",
    "\n",
    "# Read text from the file\n",
    "with open(\"hi_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Tokenize text using the BERT tokenizer\n",
    "tokens1 = tokenizer1.tokenize(text)\n",
    "#print(tokens1)\n",
    "\n",
    "#Repeat the same for max length=2000\n",
    "tokenizer2 = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    max_length=2000,\n",
    "    do_basic_tokenize=False\n",
    ")\n",
    "\n",
    "tokens2 = tokenizer2.tokenize(text)\n",
    "# print(tokens2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSQ5zEcnGkdB"
   },
   "source": [
    "UNICODE CORRECTION ON TOKENIZED FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "3OkKcFwz38lK"
   },
   "outputs": [],
   "source": [
    "tokens1 = [i.lstrip('#') for i in tokens1]\n",
    "tokens2 = [i.lstrip('#') for i in tokens2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "zxlKYr_uBovz"
   },
   "outputs": [],
   "source": [
    "# Remove items containing digits from tokens1 and tokens2\n",
    "tokens1 = [token for token in tokens1 if not token.isdigit()]\n",
    "tokens2 = [token for token in tokens2 if not token.isdigit()]\n",
    "\n",
    "# Initialize lists to store corrected tokens\n",
    "corrected_tokens_1k = []\n",
    "corrected_tokens_2k = []\n",
    "\n",
    "# Apply token_unicode_corrector to each token in tokens1 and tokens2\n",
    "for tokens in [tokens1, tokens2]:\n",
    "    for text in tokens:\n",
    "        corrected_tokens = [token_unicode_corrector(token) for token in text.split()]\n",
    "        if tokens is tokens1:\n",
    "            corrected_tokens_1k.extend(corrected_tokens)\n",
    "        else:\n",
    "            corrected_tokens_2k.extend(corrected_tokens)\n",
    "\n",
    "# Print the corrected tokens\n",
    "# print(corrected_tokens_1k)\n",
    "# print(corrected_tokens_2k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euzNZie_JYWw"
   },
   "source": [
    "COUNTING FREQUENCIES, VOCAB SIZE=1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdU5sj4vJYMR",
    "outputId": "460ba69c-8292-41bd-f2bd-17c5db71537b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 372819\n",
      "आ -> 81979\n",
      "क् -> 73828\n",
      "र् -> 69838\n",
      "ए -> 67481\n",
      "न् -> 44060\n",
      "स् -> 42122\n",
      "ई -> 41320\n",
      "ह् -> 37811\n",
      "म् -> 34347\n",
      "त् -> 32398\n",
      "ल् -> 30316\n",
      "इ -> 30041\n",
      "प् -> 26528\n",
      "य् -> 24795\n",
      "् -> 21305\n",
      "व् -> 20354\n",
      "ओ -> 19930\n",
      "द् -> 19693\n",
      "ज् -> 18214\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 53945\n",
      "स्अ -> 26846\n",
      "क्अ -> 25883\n",
      "न्अ -> 24386\n",
      "प्अ -> 20097\n",
      "अर् -> 19706\n",
      "म्अ -> 17919\n",
      "त्अ -> 16318\n",
      "ल्अ -> 16310\n",
      "क्ए -> 13397\n",
      "ब्अ -> 12430\n",
      "ह्अ -> 11582\n",
      "ग्अ -> 11486\n",
      "य्अ -> 11194\n",
      "व्अ -> 10273\n",
      "न्ए -> 10151\n",
      "ह्ऐ -> 10028\n",
      "अन् -> 9985\n",
      "ज्अ -> 9747\n",
      "क्आ -> 9714\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_tokens_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xeSLGl8MAIM",
    "outputId": "d91e1332-0db5-409c-f69f-8d9bab517a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 46946\n",
      "स -> 25604\n",
      "क -> 24837\n",
      "न -> 23886\n",
      "प -> 19939\n",
      "म -> 16748\n",
      "ल -> 15515\n",
      "त -> 14000\n",
      "के -> 13397\n",
      "ब -> 12407\n",
      "ह -> 11575\n",
      "ग -> 11193\n",
      "ने -> 10137\n",
      "है -> 10028\n",
      "का -> 9617\n",
      "ए -> 9597\n",
      "मे -> 9269\n",
      "ज -> 9200\n",
      "द -> 8768\n",
      "व -> 8452\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 6795\n",
      "पर -> 4253\n",
      "और -> 3896\n",
      "[U -> 3159\n",
      "UN -> 3159\n",
      "NK -> 3159\n",
      "K] -> 3159\n",
      "इस -> 2848\n",
      "एक -> 1980\n",
      "लिए -> 1831\n",
      "नही -> 1557\n",
      "कार -> 1490\n",
      "अप -> 1344\n",
      "किया -> 1255\n",
      "ड़ -> 1166\n",
      "यह -> 1154\n",
      "हर -> 1138\n",
      "कहा -> 1071\n",
      "उन -> 1054\n",
      "गया -> 1012\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhQTy_suOB44",
    "outputId": "27f7df74-7ef8-466a-db1f-7f713a75de50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "के: 11666\n",
      "स: 10797\n",
      "प: 10217\n",
      "र: 9991\n",
      "म: 9648\n",
      "।: 9174\n",
      "में: 8280\n",
      "ब: 8261\n",
      "न: 7766\n",
      "है: 7284\n",
      "की: 7216\n",
      "ा: 6632\n",
      "ल: 6382\n",
      "क: 6339\n",
      "को: 5865\n",
      "ने: 5732\n",
      "ी: 5704\n",
      "से: 5468\n",
      "का: 5260\n",
      "ज: 4973\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('है', '।'): 3069\n",
      "('के', 'लिए'): 1513\n",
      "('प', '्र'): 1273\n",
      "('हैं', '।'): 1144\n",
      "('आ', 'प'): 901\n",
      "('है', 'कि'): 874\n",
      "('के', 'साथ'): 651\n",
      "('ों', 'के'): 584\n",
      "('म', 'ु'): 543\n",
      "('स', 'म'): 542\n",
      "('स', 'ु'): 542\n",
      "('कहा', 'कि'): 528\n",
      "('ज', 'र'): 523\n",
      "('ब', 'ता'): 513\n",
      "('के', 'बाद'): 480\n",
      "('स', 'ा'): 479\n",
      "('ों', 'में'): 479\n",
      "('ों', 'को'): 457\n",
      "('म', 'ो'): 455\n",
      "('प', 'ह'): 454\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXPOQlU138lL"
   },
   "source": [
    "COUNTING FREQUENCIES, VOCAB SIZE=2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UnM07DE38lM",
    "outputId": "1663d31e-f2ae-40bf-89c2-6854125f9748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 372819\n",
      "आ -> 81979\n",
      "क् -> 73828\n",
      "र् -> 69838\n",
      "ए -> 67481\n",
      "न् -> 44060\n",
      "स् -> 42122\n",
      "ई -> 41320\n",
      "ह् -> 37811\n",
      "म् -> 34347\n",
      "त् -> 32398\n",
      "ल् -> 30316\n",
      "इ -> 30041\n",
      "प् -> 26528\n",
      "य् -> 24795\n",
      "् -> 21305\n",
      "व् -> 20354\n",
      "ओ -> 19930\n",
      "द् -> 19693\n",
      "ज् -> 18214\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 53945\n",
      "स्अ -> 26846\n",
      "क्अ -> 25883\n",
      "न्अ -> 24386\n",
      "प्अ -> 20097\n",
      "अर् -> 19706\n",
      "म्अ -> 17919\n",
      "त्अ -> 16318\n",
      "ल्अ -> 16310\n",
      "क्ए -> 13397\n",
      "ब्अ -> 12430\n",
      "ह्अ -> 11582\n",
      "ग्अ -> 11486\n",
      "य्अ -> 11194\n",
      "व्अ -> 10273\n",
      "न्ए -> 10151\n",
      "ह्ऐ -> 10028\n",
      "अन् -> 9985\n",
      "ज्अ -> 9747\n",
      "क्आ -> 9714\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_tokens_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdQVZ5NQ38lM",
    "outputId": "0daee6f4-069d-4e80-94e4-a6188a206179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 46946\n",
      "स -> 25604\n",
      "क -> 24837\n",
      "न -> 23886\n",
      "प -> 19939\n",
      "म -> 16748\n",
      "ल -> 15515\n",
      "त -> 14000\n",
      "के -> 13397\n",
      "ब -> 12407\n",
      "ह -> 11575\n",
      "ग -> 11193\n",
      "ने -> 10137\n",
      "है -> 10028\n",
      "का -> 9617\n",
      "ए -> 9597\n",
      "मे -> 9269\n",
      "ज -> 9200\n",
      "द -> 8768\n",
      "व -> 8452\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 6795\n",
      "पर -> 4253\n",
      "और -> 3896\n",
      "[U -> 3159\n",
      "UN -> 3159\n",
      "NK -> 3159\n",
      "K] -> 3159\n",
      "इस -> 2848\n",
      "एक -> 1980\n",
      "लिए -> 1831\n",
      "नही -> 1557\n",
      "कार -> 1490\n",
      "अप -> 1344\n",
      "किया -> 1255\n",
      "ड़ -> 1166\n",
      "यह -> 1154\n",
      "हर -> 1138\n",
      "कहा -> 1071\n",
      "उन -> 1054\n",
      "गया -> 1012\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLOAOzyj38lM",
    "outputId": "1f832511-7b1f-453e-de32-f81b5c4ee8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "के: 11666\n",
      "स: 10797\n",
      "प: 10217\n",
      "र: 9991\n",
      "म: 9648\n",
      "।: 9174\n",
      "में: 8280\n",
      "ब: 8261\n",
      "न: 7766\n",
      "है: 7284\n",
      "की: 7216\n",
      "ा: 6632\n",
      "ल: 6382\n",
      "क: 6339\n",
      "को: 5865\n",
      "ने: 5732\n",
      "ी: 5704\n",
      "से: 5468\n",
      "का: 5260\n",
      "ज: 4973\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('है', '।'): 3069\n",
      "('के', 'लिए'): 1513\n",
      "('प', '्र'): 1273\n",
      "('हैं', '।'): 1144\n",
      "('आ', 'प'): 901\n",
      "('है', 'कि'): 874\n",
      "('के', 'साथ'): 651\n",
      "('ों', 'के'): 584\n",
      "('म', 'ु'): 543\n",
      "('स', 'म'): 542\n",
      "('स', 'ु'): 542\n",
      "('कहा', 'कि'): 528\n",
      "('ज', 'र'): 523\n",
      "('ब', 'ता'): 513\n",
      "('के', 'बाद'): 480\n",
      "('स', 'ा'): 479\n",
      "('ों', 'में'): 479\n",
      "('ों', 'को'): 457\n",
      "('म', 'ो'): 455\n",
      "('प', 'ह'): 454\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxHOF7Ib38lM"
   },
   "source": [
    "**IndicBERT TOKENIZER WITH MAX LENGTH=1000 AND 2000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "45ee1503a79d43e78168edbb0873d6f3",
      "c608d1fdb97741c79116238567902c56",
      "e2425ca23c784bb7a777eed1bef7c7e3",
      "7dbc9fc20d69436d84b2042d141f849f",
      "8adeab3b7d6d4081af29da5096c25adf",
      "24599408cb95423c961f1a4bb7f031fb",
      "7a144da05ca84d57a8139623c0faaab5",
      "0bd2a859068b4f70a2dd1ce3019e43a5",
      "e495a2fddf5b4cd0b28f2380afdc6be6",
      "ff9fbe72307a42ff841908351b684ea3",
      "64a7c7f54f8948d5966419069558f04b",
      "ba766da0e0b043778925647ca5b5f4c0",
      "57af896b2e9842889a57872899260475",
      "569557395ae84a028ce6efefe91016bc",
      "e9516924c2ca4ff7a59d0671f287316e",
      "c1a6d3a765d04bd4a90808e043af64a2",
      "f68d29dbc7c24faea803dde9317d63cb",
      "54f1c368762e4904bf294bbeb6b321d9",
      "a4359a93a0ef456da8a7a91318f887bf",
      "11ee608fa5464d29be41691db0324eba",
      "f04776bbda764b93a42ca55a3cc6db1f",
      "6da541edbb6d4ce4b4e89d8679a81137"
     ]
    },
    "id": "sOBDlHF138lM",
    "outputId": "6ea72436-6ae8-4b06-ef69-5c06ff4f0672"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ee1503a79d43e78168edbb0873d6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba766da0e0b043778925647ca5b5f4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "\n",
    "# Read text from the file\n",
    "with open(\"hi_100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Load IndicBERT tokenizer and define max length of vocabulary=1000\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "tokenizer1.max_model_input_sizes = {\"ai4bharat/indic-bert\": 1000}\n",
    "\n",
    "# Tokenize text and remove garbage characters and numbers\n",
    "tokens1 = tokenizer1.tokenize(text)\n",
    "tokens1 = [word.replace(\"▁\", \"\") for word in tokens1]\n",
    "\n",
    "for i in tokens1:\n",
    "    if(i.isdigit()):\n",
    "        tokens1.remove(i)\n",
    "for i in tokens1:\n",
    "    if(i in garbage):\n",
    "        tokens1.remove(i)\n",
    "#print(tokens1)\n",
    "\n",
    "# Load IndicBERT tokenizer and define max length of vocabulary=2000\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "tokenizer2.max_model_input_sizes = {\"ai4bharat/indic-bert\": 2000}\n",
    "\n",
    "# Tokenize text and remove garbage characters and numbers\n",
    "tokens2 = tokenizer2.tokenize(text)\n",
    "tokens2 = [word.replace(\"▁\", \"\") for word in tokens2]\n",
    "\n",
    "for i in tokens2:\n",
    "    if(i.isdigit()):\n",
    "        tokens2.remove(i)\n",
    "for i in tokens2:\n",
    "    if(i in garbage):\n",
    "        tokens2.remove(i)\n",
    "# Filter out strings that represent numbers\n",
    "tokens2 = [string for string in tokens2 if not string.replace('.', '', 1).isdigit()]\n",
    "\n",
    "# print(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4lDYT3F38lN"
   },
   "source": [
    "UNICODE CORRECTION ON TOKENIZED FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "QNYaRqQE38lN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over each decoded text\n",
    "for text in tokens1:\n",
    "    # Apply the token_unicode_corrector function to each token in the decoded text\n",
    "    for token in text.split():\n",
    "        corrected_tokens_1k.append(token_unicode_corrector(token))\n",
    "\n",
    "# Print the corrected tokens\n",
    "# print(corrected_tokens_1k)\n",
    "\n",
    "\n",
    "corrected_tokens_2k = []\n",
    "\n",
    "# Iterate over each decoded text\n",
    "for text in tokens2:\n",
    "    # Apply the token_unicode_corrector function to each token in the decoded text\n",
    "    for token in text.split():\n",
    "        corrected_tokens_2k.append(token_unicode_corrector(token))\n",
    "\n",
    "# Print the corrected tokens\n",
    "# print(corrected_tokens_2k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YX2G8B038lN"
   },
   "source": [
    "COUNTING FREQUENCIES, VOCAB SIZE=1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrOHTDic38lN",
    "outputId": "452ee34d-f88a-4c2a-9208-b57e8ce871e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 1601953\n",
      "क् -> 222904\n",
      "र् -> 211216\n",
      "न् -> 133238\n",
      "स् -> 127440\n",
      "ह् -> 114019\n",
      "म् -> 103899\n",
      "त् -> 98202\n",
      "आ -> 95979\n",
      "ल् -> 91844\n",
      "ए -> 86807\n",
      "प् -> 80518\n",
      "य् -> 75211\n",
      "व् -> 61568\n",
      "द् -> 59565\n",
      "ज् -> 55368\n",
      "ब् -> 51563\n",
      "ई -> 49672\n",
      "ग् -> 47879\n",
      "इ -> 42567\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 195323\n",
      "क्अ -> 174959\n",
      "अर् -> 122448\n",
      "न्अ -> 113564\n",
      "स्अ -> 112164\n",
      "ह्अ -> 87790\n",
      "म्अ -> 87471\n",
      "त्अ -> 82122\n",
      "ल्अ -> 77838\n",
      "प्अ -> 74087\n",
      "य्अ -> 61610\n",
      "अन् -> 56467\n",
      "व्अ -> 51487\n",
      "द्अ -> 49246\n",
      "ब्अ -> 47082\n",
      "ज्अ -> 46901\n",
      "ग्अ -> 43564\n",
      "अल् -> 37309\n",
      "अह् -> 36872\n",
      "अत् -> 34207\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_tokens_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_j3hErzw38lO",
    "outputId": "1d070603-6e7f-426e-ba62-01b2e605e155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "क -> 74538\n",
      "र -> 70689\n",
      "न -> 44589\n",
      "स -> 42659\n",
      "ह -> 38104\n",
      "म -> 34776\n",
      "त -> 32902\n",
      "ल -> 30764\n",
      "प -> 26995\n",
      "य -> 25208\n",
      "व -> 20607\n",
      "द -> 19936\n",
      "ज -> 18577\n",
      "ब -> 17326\n",
      "ग -> 16039\n",
      "ट -> 10611\n",
      "श -> 9772\n",
      "ए -> 9663\n",
      "च -> 9092\n",
      "अ -> 8468\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 11167\n",
      "पर -> 10487\n",
      "और -> 3915\n",
      "इस -> 3421\n",
      "तर -> 3198\n",
      "रह -> 3043\n",
      "वर -> 3032\n",
      "रत -> 2713\n",
      "दर -> 2562\n",
      "सम -> 2389\n",
      "सर -> 2340\n",
      "जन -> 2281\n",
      "गर -> 2267\n",
      "लग -> 2244\n",
      "एक -> 2052\n",
      "मन -> 2051\n",
      "बर -> 1980\n",
      "पन -> 1977\n",
      "उन -> 1935\n",
      "लक -> 1877\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eqqd2JAL38lO",
    "outputId": "73c1e539-8549-42b0-c057-870aca9ac34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "क: 38460\n",
      "ह: 17880\n",
      "य: 15192\n",
      "न: 13775\n",
      "स: 12805\n",
      "म: 12018\n",
      "त: 10595\n",
      "पर: 9390\n",
      ": 8673\n",
      "कर: 7020\n",
      "द: 6178\n",
      "ल: 5798\n",
      "व: 5401\n",
      "ग: 5254\n",
      "ज: 5143\n",
      "र: 4873\n",
      "थ: 4753\n",
      "ए: 4605\n",
      "भ: 4056\n",
      "और: 3901\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('न', 'ह'): 2066\n",
      "('त', 'ह'): 2008\n",
      "('क', 'य'): 1992\n",
      "('य', 'क'): 1940\n",
      "('ल', 'ए'): 1878\n",
      "('क', 'ल'): 1690\n",
      "('न', 'क'): 1614\n",
      "('ह', 'क'): 1564\n",
      "('स', 'थ'): 1448\n",
      "('ग', 'य'): 1363\n",
      "('क', 'स'): 1319\n",
      "('क', ''): 1231\n",
      "('रह', 'ह'): 1213\n",
      "('', 'दन'): 1132\n",
      "('य', 'ह'): 1125\n",
      "('क', 'पर'): 1092\n",
      "('त', 'क'): 940\n",
      "('य', 'ग'): 881\n",
      "('द', 'य'): 876\n",
      "('', 'वल'): 850\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5O3Arg_g38lO",
    "outputId": "793e84ae-5bcf-422e-bccb-887d9fe53aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 612159\n",
      "क् -> 74538\n",
      "र् -> 70689\n",
      "न् -> 44589\n",
      "स् -> 42659\n",
      "ह् -> 38104\n",
      "म् -> 34776\n",
      "त् -> 32902\n",
      "ल् -> 30764\n",
      "प् -> 26995\n",
      "य् -> 25208\n",
      "व् -> 20607\n",
      "द् -> 19936\n",
      "ज् -> 18577\n",
      "ब् -> 17326\n",
      "ग् -> 16039\n",
      "ट् -> 10611\n",
      "श् -> 9772\n",
      "ए -> 9663\n",
      "च् -> 9092\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "क्अ -> 74538\n",
      "र्अ -> 70689\n",
      "अर् -> 51371\n",
      "न्अ -> 44589\n",
      "स्अ -> 42659\n",
      "ह्अ -> 38104\n",
      "म्अ -> 34776\n",
      "त्अ -> 32902\n",
      "ल्अ -> 30764\n",
      "प्अ -> 26995\n",
      "य्अ -> 25208\n",
      "अन् -> 23241\n",
      "व्अ -> 20607\n",
      "द्अ -> 19936\n",
      "ज्अ -> 18577\n",
      "अल् -> 17350\n",
      "ब्अ -> 17326\n",
      "ग्अ -> 16039\n",
      "अत् -> 14210\n",
      "अह् -> 13666\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_tokens_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCagu6t638lO",
    "outputId": "ea0190f9-8978-4c89-b21c-2718cb3c51e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "क -> 74538\n",
      "र -> 70689\n",
      "न -> 44589\n",
      "स -> 42659\n",
      "ह -> 38104\n",
      "म -> 34776\n",
      "त -> 32902\n",
      "ल -> 30764\n",
      "प -> 26995\n",
      "य -> 25208\n",
      "व -> 20607\n",
      "द -> 19936\n",
      "ज -> 18577\n",
      "ब -> 17326\n",
      "ग -> 16039\n",
      "ट -> 10611\n",
      "श -> 9772\n",
      "ए -> 9663\n",
      "च -> 9092\n",
      "अ -> 8468\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 11167\n",
      "पर -> 10487\n",
      "और -> 3915\n",
      "इस -> 3421\n",
      "तर -> 3198\n",
      "रह -> 3043\n",
      "वर -> 3032\n",
      "रत -> 2713\n",
      "दर -> 2562\n",
      "सम -> 2389\n",
      "सर -> 2340\n",
      "जन -> 2281\n",
      "गर -> 2267\n",
      "लग -> 2244\n",
      "एक -> 2052\n",
      "मन -> 2051\n",
      "बर -> 1980\n",
      "पन -> 1977\n",
      "उन -> 1935\n",
      "लक -> 1877\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjeF8xNB38lO",
    "outputId": "510d7fda-2246-47dd-f9bb-f7bb3f69e6a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "क: 38460\n",
      "ह: 17880\n",
      "य: 15192\n",
      "न: 13775\n",
      "स: 12805\n",
      "म: 12018\n",
      "त: 10595\n",
      "पर: 9390\n",
      ": 8673\n",
      "कर: 7020\n",
      "द: 6178\n",
      "ल: 5798\n",
      "व: 5401\n",
      "ग: 5254\n",
      "ज: 5143\n",
      "र: 4873\n",
      "थ: 4753\n",
      "ए: 4605\n",
      "भ: 4056\n",
      "और: 3901\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('न', 'ह'): 2066\n",
      "('त', 'ह'): 2009\n",
      "('क', 'य'): 1992\n",
      "('य', 'क'): 1942\n",
      "('ल', 'ए'): 1879\n",
      "('क', 'ल'): 1690\n",
      "('न', 'क'): 1615\n",
      "('ह', 'क'): 1569\n",
      "('स', 'थ'): 1448\n",
      "('ग', 'य'): 1363\n",
      "('क', 'स'): 1326\n",
      "('क', ''): 1237\n",
      "('रह', 'ह'): 1213\n",
      "('', 'दन'): 1132\n",
      "('य', 'ह'): 1125\n",
      "('क', 'पर'): 1093\n",
      "('त', 'क'): 941\n",
      "('य', 'ग'): 881\n",
      "('द', 'य'): 877\n",
      "('', 'वल'): 850\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0suPoePA38lP"
   },
   "source": [
    "**WHITE SPACE TOKENIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "ZChNYwOQ38lP"
   },
   "outputs": [],
   "source": [
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the content of the file\n",
    "    content = file.read()\n",
    "    # Remove garbage characters from the content\n",
    "    for char in garbage:\n",
    "        content = content.replace(char, '')\n",
    "    # Split the content into words\n",
    "    words = content.split()\n",
    "\n",
    "# Filter out non-Hindi words\n",
    "token_ws = [word for word in words if is_hindi(word)]\n",
    "\n",
    "corrected_token_ws=[]\n",
    "for word in token_ws:\n",
    "    corrected_token_ws.append(unicode_corrector(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTOPD2jq38lP",
    "outputId": "fff10fc9-657e-4c6f-d83f-5d9c4a7643ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 frequent unigram characters:\n",
      "अ -> 230293\n",
      "आ -> 96197\n",
      "ए -> 75300\n",
      "क् -> 72255\n",
      "र् -> 68080\n",
      "ई -> 46713\n",
      "इ -> 46305\n",
      "न् -> 43186\n",
      "स् -> 41313\n",
      "ह् -> 37398\n",
      "म् -> 33844\n",
      "त् -> 31798\n",
      "ल् -> 29079\n",
      "ओ -> 28801\n",
      "प् -> 25554\n",
      "य् -> 24279\n",
      "व् -> 19893\n",
      "द् -> 19458\n",
      "उ -> 19011\n",
      "ज् -> 17440\n",
      "\n",
      "Top 20 frequent bigram characters:\n",
      "र्अ -> 38283\n",
      "अर् -> 25214\n",
      "क्अ -> 19791\n",
      "स्अ -> 18685\n",
      "न्अ -> 16847\n",
      "अन् -> 14077\n",
      "क्ए -> 13640\n",
      "प्अ -> 13005\n",
      "अह् -> 12799\n",
      "आर् -> 12147\n",
      "त्अ -> 11769\n",
      "अक् -> 11764\n",
      "म्अ -> 11336\n",
      "अत् -> 11228\n",
      "न्ए -> 10763\n",
      "ल्अ -> 10544\n",
      "क्आ -> 10123\n",
      "ह्ऐ -> 10056\n",
      "म्ए -> 9851\n",
      "य्आ -> 9652\n"
     ]
    }
   ],
   "source": [
    "#characters\n",
    "freq_module_char(corrected_token_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SG78bXfZ38lP",
    "outputId": "89ba44a2-e043-47fe-f576-fb1e01bd0e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 most occurring unigram syllables:\n",
      "र -> 32936\n",
      "क -> 19439\n",
      "स -> 17857\n",
      "न -> 16519\n",
      "के -> 13586\n",
      "प -> 12561\n",
      "ने -> 10742\n",
      "म -> 10465\n",
      "ल -> 10443\n",
      "त -> 10278\n",
      "है -> 10051\n",
      "का -> 9900\n",
      "मे -> 9744\n",
      "ए -> 9439\n",
      "ह -> 9239\n",
      "अ -> 8235\n",
      "की -> 7852\n",
      "ब -> 7589\n",
      "या -> 7333\n",
      "ग -> 7215\n",
      "\n",
      "First 20 most occurring bigram syllables:\n",
      "कर -> 5298\n",
      "और -> 3901\n",
      "पर -> 3316\n",
      "इस -> 2802\n",
      "लिए -> 1866\n",
      "एक -> 1861\n",
      "नही -> 1625\n",
      "अप -> 1525\n",
      "कार -> 1272\n",
      "किया -> 1264\n",
      "रने -> 1149\n",
      "कहा -> 1062\n",
      "यह -> 1050\n",
      "गया -> 1018\n",
      "सर -> 1013\n",
      "आप -> 989\n",
      "उस -> 982\n",
      "साथ -> 980\n",
      "उन -> 979\n",
      "सके -> 958\n"
     ]
    }
   ],
   "source": [
    "#syllables\n",
    "freq_module_syllable(token_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bm4XJgYq38lP",
    "outputId": "75d868f4-3ce4-46c6-b342-52c0d1d7e880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigram frequencies of tokens:\n",
      "के: 10662\n",
      "में: 8045\n",
      "है: 7136\n",
      "की: 6637\n",
      "को: 4862\n",
      "से: 4613\n",
      "और: 3876\n",
      "का: 3537\n",
      "ने: 3390\n",
      "पर: 2988\n",
      "हैं: 2719\n",
      "कि: 2662\n",
      "भी: 2146\n",
      "लिए: 1703\n",
      "एक: 1703\n",
      "इस: 1621\n",
      "नहीं: 1553\n",
      "कर: 1501\n",
      "ही: 1323\n",
      "किया: 1248\n",
      "\n",
      "Top 20 bigram frequencies of tokens:\n",
      "('के', 'लिए'): 1496\n",
      "('है', 'कि'): 866\n",
      "('के', 'साथ'): 601\n",
      "('कहा', 'कि'): 527\n",
      "('के', 'बाद'): 477\n",
      "('रहा', 'है'): 386\n",
      "('है', 'और'): 385\n",
      "('ने', 'कहा'): 376\n",
      "('गया', 'है'): 364\n",
      "('रहे', 'हैं'): 340\n",
      "('करने', 'के'): 308\n",
      "('रही', 'है'): 277\n",
      "('जाता', 'है'): 269\n",
      "('किया', 'गया'): 241\n",
      "('होता', 'है'): 226\n",
      "('नहीं', 'है'): 220\n",
      "('सकते', 'हैं'): 214\n",
      "('बताया', 'कि'): 210\n",
      "('कर', 'दिया'): 203\n",
      "('हैं', 'और'): 202\n"
     ]
    }
   ],
   "source": [
    "#tokens\n",
    "freq_module_strings(token_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71m49tul6zYT"
   },
   "source": [
    "**QUESTION 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBptAbcICLMY"
   },
   "source": [
    "**SENTENCES AND GROUND TRUTH DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nBygDAHGCTk2"
   },
   "outputs": [],
   "source": [
    "SentencesCS689=[\n",
    "    [\"रशीदा अपनी एकमात्र गुड़िया को पकड़े खड़ी थी, जो तब से उसके पास थी जब उसकी आयु तीन वर्ष की थी।\"],\n",
    "    [\"कई दिनाें तक ललचाने के बाद अचानक वे गायब हो गए। पिछले 10-12 साल के रेकार्ड पर नजर दौड़ाएं तो बारिश इतनी लेट कभी नहीं हुई थी। \"],\n",
    "    [\"यॉर्कशायर के पुलिस ऑफिसर मार्टिक विलीस ने हाईवे पर दुर्घटनाग्रस्थ गाड़ी को ब्रिज से गिरने से बचाया था\"],\n",
    "    [\"उन्होंने सऊदी अरब की नीतियों को लेकर कहा कि सऊदी अरब की सरकार को अगर अपनी तरक़्क़ी और इलाक़े की सुरक्षा है तो उसे फूट डालने की अपनी नीतियों, और पड़ोसियों पर हमले की राजनीति को छोड़ना होगा\"],\n",
    "    [\"'चिंता न करें'\"],\n",
    "    [\"कैरीजेन का ज्यादातर जीवन फिटनेस के आसपास ही घूमता रहा। ट्रेनिंग के केवल एक साल के बाद उन्होंने एक बेहतर शरीर का निर्माण किया उसके बाद उन्होंने फिटनेस प्रतियोगिता में भाग लेकर जीत को हासिल कर लिया।\"],\n",
    "    [\"महंगाई दर में इजाफे की वजह महंगी सब्जियां और पेट्रोल डीजल की कीमतों में इजाफा बताया गया है। \"],\n",
    "    [\"वह कई महीने से टेंट का सामान किराये पर देने के नाम पर गायब करता जा रहा था।\"],\n",
    "    [\"हालांकि टीम को पाकिस्तान जाने की इजाज़त फिलहाल भारत सरकार ने नहीं दी है\"],\n",
    "    [\"विद्यालय प्रधानाचार्य अरुण गुप्ता ने विद्यालय की वार्षिक रिपोर्ट पेश की और विद्यालय में पेश आ रही समस्याओं के बारे में सरकारी प्रतिनिधियों को अवगत करवाया।\"],\n",
    "    [\"सही बात ….. कई तरह के अनर्गल वार्तालाप से अच्छा है कुछ पढ़ा जाये या लिखा जाय…… ब्लोगिंग इसमें बहुत काम आती है। आपसे सहमत हूँ ।\"],\n",
    "    [\"इस आम चुनाव में भाजपा नेता सतीश कुमार गौतम को सबसे अधिक 6 लाख 56 हजार 215 वोट प्राप्त हुए\"],\n",
    "    [\"लेकिन आज का जनतंत्र राजनीतिक दलों की प्रतिस्पर्धा में फंसकर रह गया है. हर मसला इन दलों के लिए एक-दूसरे के ऊपर कीचड़ उछालने का मौका होता है\"],\n",
    "    [\"भारत अभी टी-20 रैंकिंग में पांचवें स्थान पर है और उसे चौथे स्थान पर पहुंचने के लिये वर्तमान सीरीज 5-0 से जीतनी होगी\"],\n",
    "    [\"उन्होंने बताया कि दूरदराज एवं गरीब तबके के लोगों को गुटखा एवं तम्बाकू सेवन से होने वाले दुष्परिणामों के बारे में अवगत कराया जाएगा।\"],\n",
    "    [\"सबका कहना है कि मोदी की बातों से साफ है कि वो भाजपा की ओर से आगामी लोकसभा चुनाव में पीएम पद के प्रत्याशी हैं और अब वो क्षेत्रीय राजनीति छोड़कर केन्द्र की राजनीति में सक्रिय में होना चाहते हैं।\"],\n",
    "    [\"तमीम इकबाल ने इस वर्ष वेस्टइंडीज दौरे पर यह उपलब्धि हासिल की थी\"],\n",
    "    [\"उन्होंने कहा, ‘भारत बहुत अधिक शुल्क लगाने वाला देश है\"],\n",
    "    [\"जनता अभी हाल ही में लोकसभा चुनाव से आई है उसे अब इतनी जल्दी ये दोहराव पसंद नही आ रहा।\"],\n",
    "    [\"बिस्तर में ही नोट मिलेंगे।\"],\n",
    "    [\"समै समै सुंदर सबै रूपु-कुरूपु न कोइ।\"],\n",
    "    [\"लेकिन इस बार मलेशिया से अंतिम लीग मैच में 0-1 से हारने के कारण भारत को तीसरे स्थान के लिए खेलने पर मजबूर होना पड़ा।\"],\n",
    "    [\"स्वास्थ्य सचिव ने कहा कि होम्योपैथिक विभाग सीधे मेरे अधीन काम करता है और अब तक किसी ने मुझसे या विभाग से संपर्क नहीं किया है।\"],\n",
    "    [\"ध्यान देने योग्य बात है कि अधिनियम की धारा 32 के तहत कुछ पद विकलांगों के लिए रखे जाते हैं।\"],\n",
    "    [\"उत्तराखण्ड आयुर्वेद विश्व विघालय के कालेजों में फीस बढ़ोत्तरी एंव छात्रों के उत्पीड़न के विरोध में उत्तराखण्ड क्रांतिदल के कार्यकताओं ने आज घंटाघर स्थित इंद्रमणी बडोनी की प्रतिमा के समीप धरना प्रदर्शन कर राज्यपाल के नाम ज्ञापन प्रेषित किया।\"]\n",
    "]\n",
    "\n",
    "ground_truth=[\n",
    "    ['रशीदा', 'अपनी एकमात्र गुड़िया को', 'पकड़े खड़ी थी', 'जो तब से', 'उसके पास थी', 'जब उसकी आयु तीन वर्ष की थी'],\n",
    "    ['कई दिनाें तक', 'ललचाने के बाद', 'अचानक', 'वे गायब हो गए।', 'पिछले 10-12 साल के रेकार्ड पर', 'नजर दौड़ाएं तो', 'बारिश इतनी लेट कभी नहीं हुई थी।'],\n",
    "    ['यॉर्कशायर के पुलिस ऑफिसर मार्टिक विलीस ने', 'हाईवे पर', 'दुर्घटनाग्रस्थ गाड़ी को', 'ब्रिज से गिरने से', 'बचाया था'],\n",
    "    ['उन्होंने', 'सऊदी अरब की नीतियों को लेकर', 'कहा कि', 'सऊदी अरब की सरकार को', 'अगर अपनी तरक़्क़ी और इलाक़े की सुरक्षा है तो', 'उसे फूट डालने की अपनी नीतियों', 'और', 'पड़ोसियों पर हमले की राजनीति को', 'छोड़ना होगा'],\n",
    "    ['चिंता न करें'],\n",
    "    ['कैरीजेन का ज्यादातर जीवन', 'फिटनेस के आसपास ही घूमता रहा।', 'ट्रेनिंग के केवल एक साल के बाद', 'उन्होंने एक बेहतर शरीर का निर्माण किया', 'उसके बाद', 'उन्होंने फिटनेस प्रतियोगिता में भाग लेकर', 'जीत को हासिल कर लिया।'],\n",
    "    ['महंगाई दर में इजाफे की वजह', 'महंगी सब्जियां और पेट्रोल डीजल की कीमतों में', 'इजाफा बताया गया है।'],\n",
    "    ['वह', 'कई महीने से', 'टेंट का सामान', 'किराये पर देने के नाम पर', 'गायब करता जा रहा था।'],\n",
    "    ['हालांकि', 'टीम को', 'पाकिस्तान जाने की इजाज़त', 'फिलहाल', 'भारत सरकार ने', 'नहीं दी है।'],\n",
    "    ['विद्यालय प्रधानाचार्य अरुण गुप्ता ने', 'विद्यालय की वार्षिक रिपोर्ट पेश की', 'और', 'विद्यालय में', 'पेश आ रही समस्याओं के बारे में', 'सरकारी प्रतिनिधियों को', 'अवगत करवाया।'],\n",
    "    ['सही बात …..', 'कई तरह के अनर्गल वार्तालाप से', 'अच्छा है', 'कुछ पढ़ा जाये या लिखा जाय……', 'ब्लोगिंग इसमें बहुत काम आती है।', 'आपसे सहमत हूँ ।'],\n",
    "    ['इस आम चुनाव में', 'भाजपा नेता सतीश कुमार गौतम को', 'सबसे अधिक', '6 लाख 56 हजार 215 वोट', 'प्राप्त हुए।'],\n",
    "    ['लेकिन आज', 'का जनतंत्र', 'राजनीतिक दलों की प्रतिस्पर्धा में', 'फंसकर रह गया है।', 'हर मसला', 'इन दलों के लिए', 'एक-दूसरे के ऊपर कीचड़ उछालने का मौका होता है।'],\n",
    "    ['भारत अभी', 'टी-20 रैंकिंग में', 'पांचवें स्थान पर है', 'और', 'उसे चौथे स्थान पर पहुंचने के लिये', 'वर्तमान सीरीज', '5-0 से जीतनी होगी।'],\n",
    "    ['उन्होंने बताया कि', 'दूरदराज एवं गरीब तबके के लोगों को', 'गुटखा एवं तम्बाकू सेवन से', 'होने वाले दुष्परिणामों के बारे में', 'अवगत कराया जाएगा।'],\n",
    "    ['सबका कहना है कि', 'मोदी की बातों से साफ है कि', 'वो भाजपा की ओर से', 'आगामी लोकसभा चुनाव में पीएम पद के प्रत्याशी हैं', 'और', 'अब', 'वो क्षेत्रीय राजनीति छोड़कर', 'केन्द्र की राजनीति में सक्रिय में होना चाहते हैं।'],\n",
    "    ['तमीम इकबाल ने', 'इस वर्ष', 'वेस्टइंडीज दौरे पर', 'यह उपलब्धि हासिल की थी।'],\n",
    "    ['उन्होंने कहा', 'भारत बहुत अधिक शुल्क लगाने वाला देश है।'],\n",
    "    ['जनता अभी,', 'हाल ही में,', 'लोकसभा चुनाव से आई है,', 'उसे अब,', 'इतनी जल्दी,', 'ये दोहराव पसंद नही आ रहा।'],\n",
    "    ['बिस्तर में ही',' नोट मिलेंगे।'],\n",
    "    ['समै समै', 'सुंदर सबै', 'रूपु-कुरूपु न कोइ।'],\n",
    "    ['लेकिन,', 'इस बार,', 'मलेशिया से,', 'अंतिम लीग मैच में,', '0-1 से हारने के कारण,', 'भारत को,', 'तीसरे स्थान के लिए,', 'खेलने पर,', 'मजबूर होना पड़ा।'],\n",
    "    ['स्वास्थ्य सचिव ने कहा कि,', 'होम्योपैथिक विभाग,', 'सीधे मेरे अधीन काम करता है,', 'और,', 'अब तक,', 'किसी ने,', 'मुझसे या विभाग से,', 'संपर्क नहीं किया है।'],\n",
    "    ['ध्यान देने योग्य बात है कि,', 'अधिनियम की धारा 32 के तहत,', 'कुछ पद,', 'विकलांगों के लिए,', 'रखे जाते हैं।'],\n",
    "    ['उत्तराखण्ड आयुर्वेद विश्व विघालय के कालेजों में,', 'फीस बढ़ोत्तरी एंव छात्रों के उत्पीड़न के विरोध में,', 'उत्तराखण्ड क्रांतिदल के कार्यकताओं ने,', 'आज, घंटाघर स्थित इंद्रमणी बडोनी की प्रतिमा के समीप,', 'धरना प्रदर्शन कर, राज्यपाल के नाम,', 'ज्ञापन प्रेषित किया।']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o0ap3ndl87kw"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_calculator(truth, sentences):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for t, s in zip(truth, sentences):\n",
    "        # Convert each sentence to lists\n",
    "        sentence_list = list(s)\n",
    "        truth_list = list(t)\n",
    "\n",
    "        # Initialize counters\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for word in sentence_list:\n",
    "            if word in truth_list:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "        for word in truth_list:\n",
    "            if word not in sentence_list:\n",
    "                fn += 1\n",
    "\n",
    "        # Update counts\n",
    "        true_positives += tp\n",
    "        false_positives += fp\n",
    "        false_negatives += fn\n",
    "\n",
    "    # Output the results\n",
    "    print(\"True Positives:\", true_positives)\n",
    "    print(\"False Positives:\", false_positives)\n",
    "    print(\"False Negatives:\", false_negatives)\n",
    "\n",
    "    return true_positives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OwCPDrt1-FTP"
   },
   "outputs": [],
   "source": [
    "def calculate_precision(tp,fp):\n",
    "    # Calculate precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    print(precision)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z9Z-LHXoBd4K"
   },
   "outputs": [],
   "source": [
    "def calculate_recall(tp,fn):\n",
    "    # Calculate recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    print(recall)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YFfMcrEaBgzy"
   },
   "outputs": [],
   "source": [
    "def calculate_fscore(precision, recall):\n",
    "    # Calculate F1-score\n",
    "    fscore = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(fscore)\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCclAWMKBriq"
   },
   "source": [
    "CALCULATING METRICS FOR UNIGRAM MODEL, V=1000 and V=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-aLNmkD0BpPZ",
    "outputId": "acc6c8db-ea06-4a04-dd2d-2dabf98fbf37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 9\n",
      "False Positives: 1046\n",
      "False Negatives: 131\n",
      "\n",
      "Precision for unigram model(V=1000) is:\n",
      "0.008530805687203791\n",
      "\n",
      "Recall for unigram model(V=1000) is:\n",
      "0.06428571428571428\n",
      "\n",
      "F-Score for unigram model(V=1000) is:\n",
      "0.01506276150627615\n",
      "\n",
      "\n",
      "True Positives: 11\n",
      "False Positives: 871\n",
      "False Negatives: 129\n",
      "\n",
      "Precision for unigram model(V=2000) is:\n",
      "0.012471655328798186\n",
      "\n",
      "Recall for unigram model(V=2000) is:\n",
      "0.07857142857142857\n",
      "\n",
      "F-Score for unigram model(V=2000) is:\n",
      "0.02152641878669276\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "#V=1K\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"unigram_model_1k.model\")\n",
    "\n",
    "tokenized_unigram1 = []\n",
    "\n",
    "for sentence in SentencesCS689:\n",
    "    words = sp.encode(sentence[0], out_type=str)\n",
    "    words = [string.replace(\"▁\", \"\") for string in words]\n",
    "    tokenized_unigram1.append(words)\n",
    "\n",
    "# print(tokenized_unigram)\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_unigram1)\n",
    "print()\n",
    "print(\"Precision for unigram model(V=1000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for unigram model(V=1000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for unigram model(V=1000) is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#V=2K\n",
    "sp.load(\"unigram_model_2k.model\")\n",
    "\n",
    "tokenized_unigram2 = []\n",
    "\n",
    "for sentence in SentencesCS689:\n",
    "    words = sp.encode(sentence[0], out_type=str)\n",
    "    words = [string.replace(\"▁\", \"\") for string in words]\n",
    "    tokenized_unigram2.append(words)\n",
    "\n",
    "# print(tokenized_unigram)\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_unigram2)\n",
    "print()\n",
    "print(\"Precision for unigram model(V=2000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for unigram model(V=2000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for unigram model(V=2000) is:\")\n",
    "f=calculate_fscore(p,r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFrjQJWx6591"
   },
   "source": [
    "CALCULATING METRICS FOR BPE MODEL, V=1000 and V=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_04Qdnhp671b",
    "outputId": "81e06746-668a-4d2f-af2e-010763513416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 8\n",
      "False Positives: 1068\n",
      "False Negatives: 132\n",
      "\n",
      "Precision for bpe model(V=1000) is:\n",
      "0.007434944237918215\n",
      "\n",
      "Recall for bpe model(V=1000) is:\n",
      "0.05714285714285714\n",
      "\n",
      "F-Score for bpe model(V=1000) is:\n",
      "0.013157894736842103\n",
      "\n",
      "\n",
      "True Positives: 9\n",
      "False Positives: 897\n",
      "False Negatives: 131\n",
      "\n",
      "Precision for bpe model(V=2000) is:\n",
      "0.009933774834437087\n",
      "\n",
      "Recall for bpe model(V=2000) is:\n",
      "0.06428571428571428\n",
      "\n",
      "F-Score for bpe model(V=2000) is:\n",
      "0.01720841300191205\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "#V=1K\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"bpe_model_1k.model\")\n",
    "\n",
    "tokenized_bpe1 = []\n",
    "\n",
    "for sentence in SentencesCS689:\n",
    "    words = sp.encode(sentence[0], out_type=str)\n",
    "    words = [string.replace(\"▁\", \"\") for string in words]\n",
    "    tokenized_bpe1.append(words)\n",
    "\n",
    "# print(tokenized_bpe)\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_bpe1)\n",
    "print()\n",
    "print(\"Precision for bpe model(V=1000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for bpe model(V=1000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for bpe model(V=1000) is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#V=2K\n",
    "sp.load(\"bpe_model_2k.model\")\n",
    "\n",
    "tokenized_bpe2 = []\n",
    "\n",
    "for sentence in SentencesCS689:\n",
    "    words = sp.encode(sentence[0], out_type=str)\n",
    "    words = [string.replace(\"▁\", \"\") for string in words]\n",
    "    tokenized_bpe2.append(words)\n",
    "\n",
    "# print(tokenized_bpe)\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_bpe2)\n",
    "print()\n",
    "print(\"Precision for bpe model(V=2000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for bpe model(V=2000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for bpe model(V=2000) is:\")\n",
    "f=calculate_fscore(p,r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eOeJYYG-l3j"
   },
   "source": [
    "CALCULATING METRICS FOR mBERT MODEL, maxLength=1000 and maxLength=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WeG_f2zG7n-m",
    "outputId": "5210c4ed-be3e-42c3-dfd3-177d9bb49afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 9\n",
      "False Positives: 1031\n",
      "False Negatives: 131\n",
      "\n",
      "Precision for mBERT model(maxLength=1000) is:\n",
      "0.008653846153846154\n",
      "\n",
      "Recall for mBERT model(maxLength=1000) is:\n",
      "0.06428571428571428\n",
      "\n",
      "F-Score for mBERT model(maxLength=1000) is:\n",
      "0.015254237288135594\n",
      "\n",
      "\n",
      "True Positives: 9\n",
      "False Positives: 1031\n",
      "False Negatives: 131\n",
      "\n",
      "Precision for mBERT model(maxLength=2000) is:\n",
      "0.008653846153846154\n",
      "\n",
      "Recall for mBERT model(maxLength=2000) is:\n",
      "0.06428571428571428\n",
      "\n",
      "F-Score for mBERT model(maxLength=2000) is:\n",
      "0.015254237288135594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the BERT tokenizer with maximum input length set to 1000\n",
    "tokenizer1 = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    max_length=1000,\n",
    "    do_basic_tokenize=False\n",
    ")\n",
    "\n",
    "tokenized_mbert1= []\n",
    "for array in SentencesCS689:\n",
    "    arr = []\n",
    "    for sentence in array:\n",
    "        # Tokenize the sentence using the BERT tokenizer\n",
    "        sen= tokenizer1.tokenize(sentence)\n",
    "        arr.append(sen)\n",
    "    tokenized_mbert1.append(arr)\n",
    "\n",
    "#converting into 2D array\n",
    "tokenized_mbert1 = [i for array in tokenized_mbert1 for i in array]\n",
    "tokenized_mbert1=[[word.replace('#', '') for word in sublist] for sublist in tokenized_mbert1]\n",
    "# print(tokenized_mbert1)\n",
    "\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_mbert1)\n",
    "print()\n",
    "print(\"Precision for mBERT model(maxLength=1000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for mBERT model(maxLength=1000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for mBERT model(maxLength=1000) is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()\n",
    "print()\n",
    "\n",
    "tokenizer2 = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    max_length=2000,\n",
    "    do_basic_tokenize=False\n",
    ")\n",
    "\n",
    "tokenized_mbert2= []\n",
    "for array in SentencesCS689:\n",
    "    arr = []\n",
    "    for sentence in array:\n",
    "        # Tokenize the sentence using the BERT tokenizer\n",
    "        sen= tokenizer2.tokenize(sentence)\n",
    "        arr.append(sen)\n",
    "    tokenized_mbert2.append(arr)\n",
    "\n",
    "#converting into 2D array\n",
    "tokenized_mbert2 = [i for array in tokenized_mbert2 for i in array]\n",
    "# print(tokenized_mbert2)\n",
    "\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_mbert2)\n",
    "print()\n",
    "print(\"Precision for mBERT model(maxLength=2000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for mBERT model(maxLength=2000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for mBERT model(maxLength=2000) is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qrnl9IeRxX0"
   },
   "source": [
    "CALCULATING METRICS FOR indicBERT MODEL, maxLength=1000 and maxLength=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roxclpiBBO8l",
    "outputId": "ee991c26-e4f8-4491-b12d-af8573ab4b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 7\n",
      "False Positives: 894\n",
      "False Negatives: 133\n",
      "\n",
      "Precision for indicBERT model(maxLength=1000) is:\n",
      "0.00776914539400666\n",
      "\n",
      "Recall for indicBERT model(maxLength=1000) is:\n",
      "0.05\n",
      "\n",
      "F-Score for indicBERT model(maxLength=1000) is:\n",
      "0.013448607108549473\n",
      "\n",
      "\n",
      "True Positives: 7\n",
      "False Positives: 894\n",
      "False Negatives: 133\n",
      "\n",
      "Precision for indicBERT model(maxLength=2000) is:\n",
      "0.00776914539400666\n",
      "\n",
      "Recall for indicBERT model(maxLength=2000) is:\n",
      "0.05\n",
      "\n",
      "F-Score for indicBERT model(maxLength=2000) is:\n",
      "0.013448607108549473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#indicBERT maxLength 1000\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Load the IndicBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "tokenizer.max_model_input_sizes = {\"ai4bharat/indic-bert\": 1000}\n",
    "# Tokenize each sentence in the array of arrays\n",
    "tokenized_indicBERT1 = [tokenizer.tokenize(sentence) for sentence_array in SentencesCS689 for sentence in sentence_array]\n",
    "tokenized_indicBERT1=[[word.replace('▁', '') for word in sublist] for sublist in tokenized_indicBERT1]\n",
    "# print(tokenized_indicBERT1)\n",
    "\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_indicBERT1)\n",
    "print()\n",
    "print(\"Precision for indicBERT model(maxLength=1000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for indicBERT model(maxLength=1000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for indicBERT model(maxLength=1000) is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()\n",
    "print()\n",
    "\n",
    "#indicBERT maxLength 2000\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "tokenizer.max_model_input_sizes = {\"ai4bharat/indic-bert\": 2000}\n",
    "tokenized_indicBERT2 = [tokenizer.tokenize(sentence) for sentence_array in SentencesCS689 for sentence in sentence_array]\n",
    "tokenized_indicBERT2=[[word.replace('▁', '') for word in sublist] for sublist in tokenized_indicBERT2]\n",
    "\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,tokenized_indicBERT2)\n",
    "print()\n",
    "print(\"Precision for indicBERT model(maxLength=2000) is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for indicBERT model(maxLength=2000) is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for indicBERT model(maxLength=2000) is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYuU4vTlSD4W"
   },
   "source": [
    "CALCULATING METRICS FOR WHITESPACE TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5207ve2iFxvw",
    "outputId": "945d976d-0e42-47ee-b635-41fac29bb6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 12\n",
      "False Positives: 535\n",
      "False Negatives: 128\n",
      "\n",
      "Precision for whitespace tokenizer is:\n",
      "0.021937842778793418\n",
      "\n",
      "Recall for whitespace tokenizer is:\n",
      "0.08571428571428572\n",
      "\n",
      "F-Score for whitespace tokenizer is:\n",
      "0.034934497816593885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "whitespace_tokenized_sentences = []\n",
    "for sentence_list in SentencesCS689:\n",
    "    whitespace_tokenized_sentence_list = []\n",
    "    for sentence in sentence_list:\n",
    "        whitespace_tokenized_sentence = sentence.split()  # Split by whitespace\n",
    "        whitespace_tokenized_sentence_list.append(whitespace_tokenized_sentence)\n",
    "    whitespace_tokenized_sentences.append(whitespace_tokenized_sentence_list)\n",
    "\n",
    "whitespace_tokenized_sentences = [i for array in whitespace_tokenized_sentences for i in array]\n",
    "# print(whitespace_tokenized_sentences)\n",
    "\n",
    "tp,fp,fn=confusion_matrix_calculator(ground_truth,whitespace_tokenized_sentences)\n",
    "print()\n",
    "print(\"Precision for whitespace tokenizer is:\")\n",
    "p=calculate_precision(tp,fp)\n",
    "print()\n",
    "print(\"Recall for whitespace tokenizer is:\")\n",
    "r=calculate_recall(tp,fn)\n",
    "print()\n",
    "print(\"F-Score for whitespace tokenizer is:\")\n",
    "f=calculate_fscore(p,r)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00772505c6934c7c9852de01dfe79882": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02428b05dea84a81ad7340c2b2bddcc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e96613a00844d459c0be0f754452c8a",
      "max": 1961828,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37e7170414b34c0192a24af4b17131cc",
      "value": 1961828
     }
    },
    "075fed85f05c4d0abf24cbde352b2334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2163800d8d1441f491f72e09c7fb3d59",
       "IPY_MODEL_02428b05dea84a81ad7340c2b2bddcc8",
       "IPY_MODEL_82335f07589347b48f88c046d43faaa3"
      ],
      "layout": "IPY_MODEL_a09bfd47e33e4854a5cac70ff5616ab1"
     }
    },
    "0bd2a859068b4f70a2dd1ce3019e43a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11ee608fa5464d29be41691db0324eba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "125dc81fa2944707bd081c39061249fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1685f8a4dee04d04b114d7e2498e0331": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a34784a3c0c46928a4f159d89537558": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0707db3fa2c426d8a790ca9ce873ae0",
      "placeholder": "​",
      "style": "IPY_MODEL_1685f8a4dee04d04b114d7e2498e0331",
      "value": " 996k/996k [00:00&lt;00:00, 5.02MB/s]"
     }
    },
    "1c14cde1581441278e4a9ba4cad54412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d120f1b36f84354a552d698c1570c91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d2bc99d54d14a7584dbcd8c0bc65ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7487d9b800bc438a9365b2a99db92f8c",
      "placeholder": "​",
      "style": "IPY_MODEL_f4bcff6d72b04623ad6c285f355f8202",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "1e6a096a8ac648f0aeb2cf71c8deffeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e96613a00844d459c0be0f754452c8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2163800d8d1441f491f72e09c7fb3d59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe19ff4e622f4a2ca7e5c3b0e46958cb",
      "placeholder": "​",
      "style": "IPY_MODEL_fac61314219f49f1b0d1354be8c5f4cf",
      "value": "tokenizer.json: 100%"
     }
    },
    "24599408cb95423c961f1a4bb7f031fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2710377e107e42ddb84d7f13be76fdb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f6bc8995cfc432c86eba609929b8c36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37e7170414b34c0192a24af4b17131cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45ee1503a79d43e78168edbb0873d6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c608d1fdb97741c79116238567902c56",
       "IPY_MODEL_e2425ca23c784bb7a777eed1bef7c7e3",
       "IPY_MODEL_7dbc9fc20d69436d84b2042d141f849f"
      ],
      "layout": "IPY_MODEL_8adeab3b7d6d4081af29da5096c25adf"
     }
    },
    "48ad886206ce4418a007f87630406cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d2bc99d54d14a7584dbcd8c0bc65ddd",
       "IPY_MODEL_7cd9e8956fc846069834db97678be5ea",
       "IPY_MODEL_55baca83487b4e348513ba429f0a9ecd"
      ],
      "layout": "IPY_MODEL_1e6a096a8ac648f0aeb2cf71c8deffeb"
     }
    },
    "4934c43ec86d42f5a9769b9d5ce4aa30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f5fc6ff879e49cc873335cb7669ab8e",
       "IPY_MODEL_844b1cdfe5184efcb6ba3ec8ff0b1e3e",
       "IPY_MODEL_1a34784a3c0c46928a4f159d89537558"
      ],
      "layout": "IPY_MODEL_fbb35283dcef4c42b179fa9af8d98bc5"
     }
    },
    "49e215b472ab4ce3b072b5af13a59b49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f5fc6ff879e49cc873335cb7669ab8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3186f242a8e4e7abec36f8816e5a7bf",
      "placeholder": "​",
      "style": "IPY_MODEL_ecb1550760714ef2b74ef05461bbfbf0",
      "value": "vocab.txt: 100%"
     }
    },
    "54f1c368762e4904bf294bbeb6b321d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55baca83487b4e348513ba429f0a9ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96a128bc9a3c4611bfa544cee0f91ab7",
      "placeholder": "​",
      "style": "IPY_MODEL_125dc81fa2944707bd081c39061249fb",
      "value": " 29.0/29.0 [00:00&lt;00:00, 816B/s]"
     }
    },
    "569557395ae84a028ce6efefe91016bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4359a93a0ef456da8a7a91318f887bf",
      "max": 5646064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11ee608fa5464d29be41691db0324eba",
      "value": 5646064
     }
    },
    "57af896b2e9842889a57872899260475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f68d29dbc7c24faea803dde9317d63cb",
      "placeholder": "​",
      "style": "IPY_MODEL_54f1c368762e4904bf294bbeb6b321d9",
      "value": "spiece.model: 100%"
     }
    },
    "57bbb86c5cbf42119ce241a76a0f968b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6235a141661841b6a4b7d7a390738d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d0f371b02244b608a8d4854ee6b1b71",
      "placeholder": "​",
      "style": "IPY_MODEL_97ffefd8d81f42309585e8d1698a62bf",
      "value": "config.json: 100%"
     }
    },
    "64a7c7f54f8948d5966419069558f04b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6da541edbb6d4ce4b4e89d8679a81137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7487d9b800bc438a9365b2a99db92f8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a144da05ca84d57a8139623c0faaab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cd9e8956fc846069834db97678be5ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c14cde1581441278e4a9ba4cad54412",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f6bc8995cfc432c86eba609929b8c36",
      "value": 29
     }
    },
    "7dbc9fc20d69436d84b2042d141f849f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff9fbe72307a42ff841908351b684ea3",
      "placeholder": "​",
      "style": "IPY_MODEL_64a7c7f54f8948d5966419069558f04b",
      "value": " 507/507 [00:00&lt;00:00, 13.0kB/s]"
     }
    },
    "82335f07589347b48f88c046d43faaa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49e215b472ab4ce3b072b5af13a59b49",
      "placeholder": "​",
      "style": "IPY_MODEL_854e860c6ef34526afbf50c322514c2d",
      "value": " 1.96M/1.96M [00:00&lt;00:00, 7.39MB/s]"
     }
    },
    "844b1cdfe5184efcb6ba3ec8ff0b1e3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf47a7f141c5487a848aed5a74d3baf7",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd9ac2286d134938be7b0fbccc4a0880",
      "value": 995526
     }
    },
    "854e860c6ef34526afbf50c322514c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8adeab3b7d6d4081af29da5096c25adf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96a128bc9a3c4611bfa544cee0f91ab7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97ffefd8d81f42309585e8d1698a62bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d0f371b02244b608a8d4854ee6b1b71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a09bfd47e33e4854a5cac70ff5616ab1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4359a93a0ef456da8a7a91318f887bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8afb1efc784497a937b54917869cbc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00772505c6934c7c9852de01dfe79882",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57bbb86c5cbf42119ce241a76a0f968b",
      "value": 625
     }
    },
    "b0707db3fa2c426d8a790ca9ce873ae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba766da0e0b043778925647ca5b5f4c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_57af896b2e9842889a57872899260475",
       "IPY_MODEL_569557395ae84a028ce6efefe91016bc",
       "IPY_MODEL_e9516924c2ca4ff7a59d0671f287316e"
      ],
      "layout": "IPY_MODEL_c1a6d3a765d04bd4a90808e043af64a2"
     }
    },
    "bf47a7f141c5487a848aed5a74d3baf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1a6d3a765d04bd4a90808e043af64a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c608d1fdb97741c79116238567902c56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24599408cb95423c961f1a4bb7f031fb",
      "placeholder": "​",
      "style": "IPY_MODEL_7a144da05ca84d57a8139623c0faaab5",
      "value": "config.json: 100%"
     }
    },
    "ce0f4ea95d94407398ddecfe2b048c34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd9ac2286d134938be7b0fbccc4a0880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de825535a35b4ba785d99c350577bf5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d120f1b36f84354a552d698c1570c91",
      "placeholder": "​",
      "style": "IPY_MODEL_2710377e107e42ddb84d7f13be76fdb2",
      "value": " 625/625 [00:00&lt;00:00, 20.4kB/s]"
     }
    },
    "e2425ca23c784bb7a777eed1bef7c7e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bd2a859068b4f70a2dd1ce3019e43a5",
      "max": 507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e495a2fddf5b4cd0b28f2380afdc6be6",
      "value": 507
     }
    },
    "e495a2fddf5b4cd0b28f2380afdc6be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e89781736dd2496094964e8a29790e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6235a141661841b6a4b7d7a390738d85",
       "IPY_MODEL_a8afb1efc784497a937b54917869cbc9",
       "IPY_MODEL_de825535a35b4ba785d99c350577bf5c"
      ],
      "layout": "IPY_MODEL_ce0f4ea95d94407398ddecfe2b048c34"
     }
    },
    "e9516924c2ca4ff7a59d0671f287316e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f04776bbda764b93a42ca55a3cc6db1f",
      "placeholder": "​",
      "style": "IPY_MODEL_6da541edbb6d4ce4b4e89d8679a81137",
      "value": " 5.65M/5.65M [00:00&lt;00:00, 21.1MB/s]"
     }
    },
    "ecb1550760714ef2b74ef05461bbfbf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f04776bbda764b93a42ca55a3cc6db1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3186f242a8e4e7abec36f8816e5a7bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4bcff6d72b04623ad6c285f355f8202": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f68d29dbc7c24faea803dde9317d63cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fac61314219f49f1b0d1354be8c5f4cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbb35283dcef4c42b179fa9af8d98bc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe19ff4e622f4a2ca7e5c3b0e46958cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff9fbe72307a42ff841908351b684ea3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
